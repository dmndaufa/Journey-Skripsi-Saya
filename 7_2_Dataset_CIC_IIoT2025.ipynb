{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "perbaikan GIR di 4.3"
      ],
      "metadata": {
        "id": "dyd6rrbF8g8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "SdpCZLa8nGCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                            accuracy_score, precision_recall_fscore_support,\n",
        "                            matthews_corrcoef)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import joblib\n",
        "import gc\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "ih9lNGYcnFh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35LaIGAyn_A8",
        "outputId": "d42a2146-1a56-446a-a804-7e68da51b9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tahapan 1: Data Loading & Preprocessing"
      ],
      "metadata": {
        "id": "u2-gNo1dmEML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Load Dataset**"
      ],
      "metadata": {
        "id": "6RaERZhrnnLD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvPwYQaNmCMc",
        "outputId": "7adfaf6c-9900-499b-ac13-c02dba55ff1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully!\n",
            "  - Total rows: 685,671\n",
            "  - Total columns: 95\n",
            "  - Memory usage: 3994.50 MB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_parquet('/content/drive/My Drive/Dataset/CIC_IIoT_2025/final_dataset.parquet')\n",
        "\n",
        "print(f\"Dataset loaded successfully!\")\n",
        "print(f\"  - Total rows: {df.shape[0]:,}\")\n",
        "print(f\"  - Total columns: {df.shape[1]}\")\n",
        "print(f\"  - Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Drop Columns yang Tidak Perlu**"
      ],
      "metadata": {
        "id": "_TPosZLIouT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define columns to drop\n",
        "drop_columns = [\n",
        "    # Metadata (tidak predictive)\n",
        "    'device_name', 'device_mac',\n",
        "    'timestamp', 'timestamp_start', 'timestamp_end',\n",
        "\n",
        "    # Labels (keep label2 only sebagai target)\n",
        "    'label_full', 'label1', 'label3', 'label4',\n",
        "\n",
        "    # List columns (pakai count saja)\n",
        "    'log_data-types',\n",
        "    'network_ips_all', 'network_ips_dst', 'network_ips_src',\n",
        "    'network_macs_all', 'network_macs_dst', 'network_macs_src',\n",
        "    'network_ports_all', 'network_ports_dst', 'network_ports_src',\n",
        "    'network_protocols_all', 'network_protocols_dst', 'network_protocols_src'\n",
        "]"
      ],
      "metadata": {
        "id": "NRtUn3mBotmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify all columns exist before dropping\n",
        "existing_drop_cols = [col for col in drop_columns if col in df.columns]\n",
        "missing_drop_cols = [col for col in drop_columns if col not in df.columns]\n",
        "\n",
        "if missing_drop_cols:\n",
        "    print(f\"Warning: Columns not found in dataset: {missing_drop_cols}\")\n",
        "\n",
        "df = df.drop(columns=existing_drop_cols)\n",
        "\n",
        "print(f\"Dropped {len(existing_drop_cols)} columns\")\n",
        "print(f\"  - Remaining columns: {df.shape[1]}\")\n",
        "print(f\"  - Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y4ORxaOpAIs",
        "outputId": "b7ea4528-58cd-470c-d092-0ef1b63c7935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 22 columns\n",
            "  - Remaining columns: 73\n",
            "  - Memory usage: 412.21 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Mengkonversi Tipe Data ke Float32 & Int32 Memory Optimization**"
      ],
      "metadata": {
        "id": "QbnOxg9ApQC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_memory = df.memory_usage(deep=True).sum() / 1024**2\n",
        "\n",
        "# Downcast integer columns (kecuali time_window dan label2)\n",
        "int_cols = df.select_dtypes(include=['int64']).columns.tolist()\n",
        "exclude_int = ['time_window', 'label2'] if 'label2' in int_cols else ['time_window']\n",
        "\n",
        "for col in int_cols:\n",
        "    if col not in exclude_int:\n",
        "        # Check if values fit in int32\n",
        "        col_min = df[col].min()\n",
        "        col_max = df[col].max()\n",
        "\n",
        "        if col_min >= np.iinfo(np.int32).min and col_max <= np.iinfo(np.int32).max:\n",
        "            df[col] = df[col].astype('int32')\n",
        "        else:\n",
        "            print(f\"   {col}: Range too large for int32, keeping int64\")"
      ],
      "metadata": {
        "id": "Uh470H2yphJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downcast float columns\n",
        "float_cols = df.select_dtypes(include=['float64']).columns.tolist()\n",
        "\n",
        "for col in float_cols:\n",
        "    df[col] = df[col].astype('float32')\n",
        "\n",
        "final_memory = df.memory_usage(deep=True).sum() / 1024**2\n",
        "memory_saved = initial_memory - final_memory\n",
        "memory_reduction = (memory_saved / initial_memory) * 100"
      ],
      "metadata": {
        "id": "iY7cbANdpsOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Memory optimization complete!\")\n",
        "print(f\"  - Initial memory: {initial_memory:.2f} MB\")\n",
        "print(f\"  - Final memory: {final_memory:.2f} MB\")\n",
        "print(f\"  - Saved: {memory_saved:.2f} MB ({memory_reduction:.1f}% reduction)\")\n",
        "\n",
        "gc.collect()  # Force garbage collection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bRmA9D_p1H0",
        "outputId": "4b615d33-9140-4e5d-c2ee-50b6059b9869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory optimization complete!\n",
            "  - Initial memory: 412.21 MB\n",
            "  - Final memory: 226.50 MB\n",
            "  - Saved: 185.71 MB (45.1% reduction)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 Cek Kualitas Data**"
      ],
      "metadata": {
        "id": "Qn0t34Zep-6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.1 Missing Values"
      ],
      "metadata": {
        "id": "dSOGRlKTm960"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum().sum()\n",
        "print(f\"  - Missing values: {missing_values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlNoGbbmqD-F",
        "outputId": "c9e505fc-7563-4386-b1ac-7400a4cf9129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Missing values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.2 Infinite Values"
      ],
      "metadata": {
        "id": "eYXvGc1NnMmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for infinite values in float columns\n",
        "inf_count = 0\n",
        "float_cols = df.select_dtypes(include=['float32']).columns\n",
        "for col in float_cols:\n",
        "    inf_count += np.isinf(df[col]).sum()\n",
        "\n",
        "print(f\"  - Infinite values: {inf_count}\")\n",
        "\n",
        "if inf_count > 0:\n",
        "    print(f\"Replacing infinite values with NaN...\")\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # Fill NaN with median\n",
        "    for col in float_cols:\n",
        "        if df[col].isnull().sum() > 0:\n",
        "            df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "    print(f\"Infinite values handled\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxuzbZUZqJY8",
        "outputId": "f430576a-e743-40c4-899a-f8e79d05c9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - Infinite values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.3 Remove All-Zero Rows"
      ],
      "metadata": {
        "id": "f4d6JCU9nXiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [col for col in df.columns if col not in ['label2', 'time_window']]\n",
        "all_zero_mask = (df[feature_cols] == 0).all(axis=1)\n",
        "zero_count = all_zero_mask.sum()\n",
        "\n",
        "print(f\" Found {zero_count:,} all-zero rows ({(zero_count/len(df)*100):.1f}%)\")\n",
        "\n",
        "if zero_count > 0:\n",
        "    df = df[~all_zero_mask].copy()\n",
        "    print(f\"  Removed {zero_count:,} invalid rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S62BtpLYoKku",
        "outputId": "532e1280-fdf3-4314-83b0-e4d71c32449f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Found 136,798 all-zero rows (20.0%)\n",
            "  Removed 136,798 invalid rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.4 Remove EXACT duplicates (same time_window)"
      ],
      "metadata": {
        "id": "5oOoFpHtno1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols_with_tw = [col for col in df.columns if col not in ['label2']]\n",
        "size_before = len(df)\n",
        "\n",
        "df = df.drop_duplicates(subset=feature_cols_with_tw, keep='first')\n",
        "\n",
        "exact_dup_removed = size_before - len(df)\n",
        "print(f\" Removed {exact_dup_removed:,} exact duplicates\")\n",
        "print(f\"  Remaining: {len(df):,} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7-apx0VouYW",
        "outputId": "0ba6acab-a074-4e3e-c1f9-a3c33a8a0716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Removed 2,231 exact duplicates\n",
            "  Remaining: 546,642 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.5 Remove TEMPORAL duplicates (different time_window)"
      ],
      "metadata": {
        "id": "eB9J6ebTnfaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_before_temporal = len(df)\n",
        "\n",
        "# Get feature columns only (exclude label2 and time_window)\n",
        "feature_cols = [col for col in df.columns if col not in ['label2', 'time_window']]\n",
        "\n",
        "print(f\"         Checking duplicates across {len(feature_cols)} features...\")\n",
        "print(f\"         (This removes rows with identical features regardless of time_window)\")\n",
        "\n",
        "# Remove duplicates based on features only\n",
        "df = df.drop_duplicates(subset=feature_cols, keep='first')\n",
        "\n",
        "temporal_dup_removed = size_before_temporal - len(df)\n",
        "print(f\"         ✓ Removed {temporal_dup_removed:,} temporal duplicates\")\n",
        "print(f\"         Remaining: {len(df):,} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpCxDj1vqSlV",
        "outputId": "b0c0adcb-beae-4621-f2c6-5dfad24eb22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Checking duplicates across 71 features...\n",
            "         (This removes rows with identical features regardless of time_window)\n",
            "         ✓ Removed 115,049 temporal duplicates\n",
            "         Remaining: 431,593 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.4.6 Final Class Distribution"
      ],
      "metadata": {
        "id": "YYt_U1rjENF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for label in sorted(df['label2'].unique()):\n",
        "    count = (df['label2'] == label).sum()\n",
        "    pct = (count / len(df)) * 100\n",
        "    print(f\"         {label:12s}: {count:7,} ({pct:5.2f}%)\")\n",
        "\n",
        "print(f\"\\n  [Summary]\")\n",
        "print(f\"    Original size:           {df.shape[0] + zero_count + exact_dup_removed + temporal_dup_removed:,}\")\n",
        "print(f\"    After zero removal:      -{zero_count:,}\")\n",
        "print(f\"    After exact dup removal: -{exact_dup_removed:,}\")\n",
        "print(f\"    After temporal dup:      -{temporal_dup_removed:,}\")\n",
        "print(f\"    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
        "print(f\"    Final size:              {len(df):,} rows\")\n",
        "print(f\"    Total removed:           {zero_count + exact_dup_removed + temporal_dup_removed:,} ({((zero_count + exact_dup_removed + temporal_dup_removed)/(len(df) + zero_count + exact_dup_removed + temporal_dup_removed)*100):.1f}%)\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTwkbBbvER3T",
        "outputId": "c3a8a055-9a2a-42bd-a9d7-5df2141488b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         benign      : 179,312 (41.55%)\n",
            "         bruteforce  :   4,626 ( 1.07%)\n",
            "         ddos        :  51,841 (12.01%)\n",
            "         dos         :  55,469 (12.85%)\n",
            "         malware     :  22,968 ( 5.32%)\n",
            "         mitm        :  23,549 ( 5.46%)\n",
            "         recon       :  86,163 (19.96%)\n",
            "         web         :   7,665 ( 1.78%)\n",
            "\n",
            "  [Summary]\n",
            "    Original size:           685,671\n",
            "    After zero removal:      -136,798\n",
            "    After exact dup removal: -2,231\n",
            "    After temporal dup:      -115,049\n",
            "    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
            "    Final size:              431,593 rows\n",
            "    Total removed:           254,078 (37.1%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5 Train/Test Split (Time-Based)**"
      ],
      "metadata": {
        "id": "k5GhW1aKqfkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_windows = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "test_windows = [9, 10]\n",
        "\n",
        "train_df = df[df['time_window'].isin(train_windows)].copy()\n",
        "test_df = df[df['time_window'].isin(test_windows)].copy()\n",
        "\n",
        "print(f\"  ✓ Split complete!\")\n",
        "print(f\"    Train: {len(train_df):,} rows ({(len(train_df)/len(df)*100):.1f}%)\")\n",
        "print(f\"    Test:  {len(test_df):,} rows ({(len(test_df)/len(df)*100):.1f}%)\")\n",
        "\n",
        "print(f\"\\n  Train distribution:\")\n",
        "for label in sorted(train_df['label2'].unique()):\n",
        "    count = (train_df['label2'] == label).sum()\n",
        "    pct = (count / len(train_df)) * 100\n",
        "    print(f\"    {label:12s}: {count:7,} ({pct:5.2f}%)\")\n",
        "\n",
        "print(f\"\\n  Test distribution:\")\n",
        "for label in sorted(test_df['label2'].unique()):\n",
        "    count = (test_df['label2'] == label).sum()\n",
        "    pct = (count / len(test_df)) * 100\n",
        "    print(f\"    {label:12s}: {count:7,} ({pct:5.2f}%)\")\n",
        "\n",
        "# Cleanup\n",
        "del df\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l991u6a6qmXt",
        "outputId": "a98ce4d5-606a-4f5b-d76a-c9b315da0f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Split complete!\n",
            "    Train: 386,274 rows (89.5%)\n",
            "    Test:  45,319 rows (10.5%)\n",
            "\n",
            "  Train distribution:\n",
            "    benign      : 163,578 (42.35%)\n",
            "    bruteforce  :   4,055 ( 1.05%)\n",
            "    ddos        :  45,744 (11.84%)\n",
            "    dos         :  49,107 (12.71%)\n",
            "    malware     :  20,195 ( 5.23%)\n",
            "    mitm        :  20,799 ( 5.38%)\n",
            "    recon       :  76,067 (19.69%)\n",
            "    web         :   6,729 ( 1.74%)\n",
            "\n",
            "  Test distribution:\n",
            "    benign      :  15,734 (34.72%)\n",
            "    bruteforce  :     571 ( 1.26%)\n",
            "    ddos        :   6,097 (13.45%)\n",
            "    dos         :   6,362 (14.04%)\n",
            "    malware     :   2,773 ( 6.12%)\n",
            "    mitm        :   2,750 ( 6.07%)\n",
            "    recon       :  10,096 (22.28%)\n",
            "    web         :     936 ( 2.07%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify NO LEAKAGE"
      ],
      "metadata": {
        "id": "TbK2UkcyEpWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [col for col in train_df.columns if col not in ['label2', 'time_window']]\n",
        "\n",
        "test_hash = test_df[feature_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
        "train_hash = train_df[feature_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
        "\n",
        "overlap = test_hash.isin(train_hash).sum()\n",
        "overlap_pct = (overlap / len(test_df)) * 100\n",
        "\n",
        "print(f\"Test rows with identical features in train: {overlap} / {len(test_df)} ({overlap_pct:.2f}%)\")\n",
        "\n",
        "if overlap == 0:\n",
        "    print(f\" SUCCESS! NO DATA LEAKAGE DETECTED!\")\n",
        "    print(f\"   Dataset is ready for unbiased evaluation!\")\n",
        "else:\n",
        "    print(f\" WARNING: Still {overlap_pct:.2f}% leakage!\")\n",
        "    print(f\"   Need further investigation...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "612LM4s3q6hm",
        "outputId": "284061ae-3a80-4252-9524-0c6adbc8f8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test rows with identical features in train: 0 / 45319 (0.00%)\n",
            " SUCCESS! NO DATA LEAKAGE DETECTED!\n",
            "   Dataset is ready for unbiased evaluation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tahapan 1 Complete - Data is CLEAN and SPLIT!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci6w22PcpmbG",
        "outputId": "78d09de2-8c32-416b-c65a-5a036d15d6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahapan 1 Complete - Data is CLEAN and SPLIT!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "wQIyq5RS8-FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tahapan 2: Exploratory Data Analysis (EDA) ##"
      ],
      "metadata": {
        "id": "CaDz-g9kqS0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Class Distribution Analysis**"
      ],
      "metadata": {
        "id": "fvsk_TdtqhSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_class_distribution(train_df, test_df, save_path='class_distribution.png'):\n",
        "    \"\"\"Plot class distribution for train and test sets\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Train distribution\n",
        "    train_counts = train_df['label2'].value_counts().sort_index()\n",
        "    axes[0].bar(range(len(train_counts)), train_counts.values,\n",
        "                color='steelblue', edgecolor='black')\n",
        "    axes[0].set_xticks(range(len(train_counts)))\n",
        "    axes[0].set_xticklabels(train_counts.index, rotation=45, ha='right')\n",
        "    axes[0].set_ylabel('Count')\n",
        "    axes[0].set_title('Train Set Class Distribution')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add percentage labels\n",
        "    for i, v in enumerate(train_counts.values):\n",
        "        pct = (v / len(train_df)) * 100\n",
        "        axes[0].text(i, v, f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    # Test distribution\n",
        "    test_counts = test_df['label2'].value_counts().sort_index()\n",
        "    axes[1].bar(range(len(test_counts)), test_counts.values,\n",
        "                color='coral', edgecolor='black')\n",
        "    axes[1].set_xticks(range(len(test_counts)))\n",
        "    axes[1].set_xticklabels(test_counts.index, rotation=45, ha='right')\n",
        "    axes[1].set_ylabel('Count')\n",
        "    axes[1].set_title('Test Set Class Distribution')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add percentage labels\n",
        "    for i, v in enumerate(test_counts.values):\n",
        "        pct = (v / len(test_df)) * 100\n",
        "        axes[1].text(i, v, f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"   Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "    # Print imbalance ratio\n",
        "    print(\"\\n   Imbalance Ratios (majority:minority):\")\n",
        "    max_count = train_counts.max()\n",
        "    for label, count in train_counts.items():\n",
        "        ratio = max_count / count\n",
        "        print(f\"      {label:12s}: 1:{ratio:.2f}\")"
      ],
      "metadata": {
        "id": "PzvPV5o280Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call function\n",
        "plot_class_distribution(train_df, test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxLCVdWG9QD3",
        "outputId": "c1f5c765-658e-4c9c-f2a7-906222d51a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Saved: class_distribution.png\n",
            "\n",
            "   Imbalance Ratios (majority:minority):\n",
            "      benign      : 1:1.00\n",
            "      bruteforce  : 1:40.34\n",
            "      ddos        : 1:3.58\n",
            "      dos         : 1:3.33\n",
            "      malware     : 1:8.10\n",
            "      mitm        : 1:7.86\n",
            "      recon       : 1:2.15\n",
            "      web         : 1:24.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Feature Correlation**"
      ],
      "metadata": {
        "id": "Nic3ut2qsjnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_feature_correlation(train_df, top_n=20, save_path='feature_correlation.png'):\n",
        "    \"\"\"Analyze correlation between features\"\"\"\n",
        "    # Get numeric features only\n",
        "    feature_cols = [col for col in train_df.columns\n",
        "                   if col not in ['label2', 'time_window']]\n",
        "\n",
        "    # Sample for memory efficiency (10k rows)\n",
        "    sample_df = train_df[feature_cols].sample(n=min(10000, len(train_df)),\n",
        "                                               random_state=42)\n",
        "\n",
        "    # Calculate correlation matrix\n",
        "    corr_matrix = sample_df.corr()\n",
        "\n",
        "    # Get top correlated pairs\n",
        "    corr_pairs = []\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i+1, len(corr_matrix.columns)):\n",
        "            corr_pairs.append((\n",
        "                corr_matrix.columns[i],\n",
        "                corr_matrix.columns[j],\n",
        "                abs(corr_matrix.iloc[i, j])\n",
        "            ))\n",
        "\n",
        "    # Sort by correlation\n",
        "    corr_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    print(f\"Top {top_n} Highly Correlated Feature Pairs:\")\n",
        "    for feat1, feat2, corr_val in corr_pairs[:top_n]:\n",
        "        print(f\"      {feat1:40s} <-> {feat2:40s}: {corr_val:.3f}\")\n",
        "\n",
        "    # Plot top correlations\n",
        "    top_features = set()\n",
        "    for feat1, feat2, _ in corr_pairs[:top_n]:\n",
        "        top_features.add(feat1)\n",
        "        top_features.add(feat2)\n",
        "\n",
        "    top_features = list(top_features)[:30]  # Limit to 30 features\n",
        "\n",
        "    plt.figure(figsize=(14, 12))\n",
        "    sns.heatmap(corr_matrix.loc[top_features, top_features],\n",
        "                cmap='coolwarm', center=0,\n",
        "                square=True, linewidths=0.5,\n",
        "                cbar_kws={\"shrink\": 0.8})\n",
        "    plt.title(f'Feature Correlation Heatmap (Top {len(top_features)} Features)')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"   Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "    del sample_df, corr_matrix\n",
        "    gc.collect()\n",
        "\n",
        "# Call function\n",
        "analyze_feature_correlation(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "632yV2af9hMP",
        "outputId": "79451985-f8d7-4583-e769-7e0685f0f5bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 Highly Correlated Feature Pairs:\n",
            "      network_macs_dst_count                   <-> network_macs_src_count                  : 1.000\n",
            "      network_header-length_avg                <-> network_header-length_min               : 1.000\n",
            "      network_mss_avg                          <-> network_mss_max                         : 1.000\n",
            "      network_header-length_avg                <-> network_header-length_max               : 1.000\n",
            "      network_header-length_max                <-> network_header-length_min               : 1.000\n",
            "      network_ip-length_max                    <-> network_packet-size_max                 : 0.999\n",
            "      network_ips_all_count                    <-> network_ips_dst_count                   : 0.999\n",
            "      network_ip-length_max                    <-> network_payload-length_max              : 0.997\n",
            "      network_packet-size_max                  <-> network_payload-length_max              : 0.997\n",
            "      log_data-ranges_avg                      <-> log_data-ranges_max                     : 0.995\n",
            "      network_mss_avg                          <-> network_mss_min                         : 0.994\n",
            "      network_macs_all_count                   <-> network_macs_dst_count                  : 0.994\n",
            "      network_macs_all_count                   <-> network_macs_src_count                  : 0.994\n",
            "      network_mss_max                          <-> network_mss_min                         : 0.994\n",
            "      network_packets_all_count                <-> network_packets_dst_count               : 0.993\n",
            "      network_ips_src_count                    <-> network_macs_dst_count                  : 0.990\n",
            "      network_ips_src_count                    <-> network_macs_src_count                  : 0.990\n",
            "      network_tcp-flags-fin_count              <-> network_tcp-flags-rst_count             : 0.987\n",
            "      network_ips_src_count                    <-> network_macs_all_count                  : 0.986\n",
            "      network_ip-length_std_deviation          <-> network_packet-size_std_deviation       : 0.982\n",
            "   Saved: feature_correlation.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 Feature Group Statistics**"
      ],
      "metadata": {
        "id": "gVpQ1_ZNsweQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_feature_groups(train_df):\n",
        "    \"\"\"Analyze statistics per feature group\"\"\"\n",
        "\n",
        "    # Define feature groups based on CIC-IIoT-2025 dataset\n",
        "    feature_groups = {\n",
        "        'log_stats': [col for col in train_df.columns if col.startswith('log_')],\n",
        "        'packet_rate': [col for col in train_df.columns\n",
        "                       if 'interval' in col or 'packets_' in col and '_count' in col],\n",
        "        'size_length': [col for col in train_df.columns\n",
        "                       if any(x in col for x in ['length', 'size', 'mss'])],\n",
        "        'tcp_flags': [col for col in train_df.columns if 'tcp-flags' in col],\n",
        "        'ip_flags': [col for col in train_df.columns if 'ip-flags' in col],\n",
        "        'address_diversity': [col for col in train_df.columns\n",
        "                             if any(x in col for x in ['ips_', 'macs_'])],\n",
        "        'network_multiplexing': [col for col in train_df.columns\n",
        "                                if any(x in col for x in ['ports_', 'protocols_'])],\n",
        "        'timing_control': [col for col in train_df.columns\n",
        "                          if any(x in col for x in ['time-delta', 'ttl', 'window-size'])],\n",
        "        'fragmentation': [col for col in train_df.columns if 'fragment' in col]\n",
        "    }\n",
        "\n",
        "    print(\"Feature Group Summary:\")\n",
        "    group_stats = {}\n",
        "    for group_name, features in feature_groups.items():\n",
        "        features = [f for f in features if f in train_df.columns]\n",
        "        if len(features) > 0:\n",
        "            group_data = train_df[features]\n",
        "            stats = {\n",
        "                'count': len(features),\n",
        "                'mean_avg': group_data.mean().mean(),\n",
        "                'mean_std': group_data.std().mean(),\n",
        "                'missing_pct': (group_data.isnull().sum().sum() /\n",
        "                               (len(group_data) * len(features))) * 100\n",
        "            }\n",
        "            group_stats[group_name] = stats\n",
        "            print(f\"      {group_name:25s}: {stats['count']:2d} features | \"\n",
        "                  f\"Avg: {stats['mean_avg']:8.2f} | \"\n",
        "                  f\"Std: {stats['mean_std']:8.2f}\")\n",
        "\n",
        "    return feature_groups, group_stats\n",
        "\n",
        "# Call function\n",
        "feature_groups, group_stats = analyze_feature_groups(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC9VJFd8-NO3",
        "outputId": "cca5b893-cdfa-41ca-b4c3-10f6d4c1e1ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Group Summary:\n",
            "      log_stats                :  7 features | Avg:    69.57 | Std:   173.79\n",
            "      packet_rate              :  5 features | Avg: 14585.04 | Std: 49261.75\n",
            "      size_length              : 24 features | Avg:  3104.45 | Std:  3014.41\n",
            "      tcp_flags                : 10 features | Avg:  2781.08 | Std: 23655.68\n",
            "      ip_flags                 :  4 features | Avg:     0.74 | Std:     0.62\n",
            "      address_diversity        :  6 features | Avg:     6.09 | Std:    13.75\n",
            "      network_multiplexing     :  6 features | Avg:  2089.34 | Std:  6647.40\n",
            "      timing_control           : 12 features | Avg:  5922.98 | Std:  5503.67\n",
            "      fragmentation            :  2 features | Avg:   635.05 | Std:  3126.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 Temporal Pattern Analysis**"
      ],
      "metadata": {
        "id": "wtsIgxE3s4YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_temporal_patterns(train_df, test_df, save_path='temporal_patterns.png'):\n",
        "    \"\"\"Analyze attack patterns across time windows\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "    # Train temporal distribution\n",
        "    train_temporal = train_df.groupby(['time_window', 'label2']).size().unstack(fill_value=0)\n",
        "    train_temporal.plot(kind='bar', stacked=True, ax=axes[0],\n",
        "                       colormap='tab10', edgecolor='black', linewidth=0.5)\n",
        "    axes[0].set_title('Train Set: Attack Distribution Across Time Windows')\n",
        "    axes[0].set_xlabel('Time Window')\n",
        "    axes[0].set_ylabel('Count')\n",
        "    axes[0].legend(title='Attack Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Test temporal distribution\n",
        "    test_temporal = test_df.groupby(['time_window', 'label2']).size().unstack(fill_value=0)\n",
        "    test_temporal.plot(kind='bar', stacked=True, ax=axes[1],\n",
        "                      colormap='tab10', edgecolor='black', linewidth=0.5)\n",
        "    axes[1].set_title('Test Set: Attack Distribution Across Time Windows')\n",
        "    axes[1].set_xlabel('Time Window')\n",
        "    axes[1].set_ylabel('Count')\n",
        "    axes[1].legend(title='Attack Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"   Saved: {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "    # Print temporal statistics\n",
        "    print(\"\\n   Temporal Statistics:\")\n",
        "    print(f\"      Train windows: {sorted(train_df['time_window'].unique())}\")\n",
        "    print(f\"      Test windows:  {sorted(test_df['time_window'].unique())}\")\n",
        "\n",
        "    for label in sorted(train_df['label2'].unique()):\n",
        "        train_windows = train_df[train_df['label2'] == label]['time_window'].value_counts()\n",
        "        print(f\"\\n      {label:12s}:\")\n",
        "        print(f\"         Appears in {len(train_windows)} windows\")\n",
        "        print(f\"         Avg per window: {train_windows.mean():.0f}\")\n",
        "        print(f\"         Std: {train_windows.std():.0f}\")\n",
        "\n",
        "# Call function\n",
        "analyze_temporal_patterns(train_df, test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEyrb7f7-b7Y",
        "outputId": "e90ccbb4-2a12-4ae2-8b9c-4c8c333b949b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Saved: temporal_patterns.png\n",
            "\n",
            "   Temporal Statistics:\n",
            "      Train windows: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]\n",
            "      Test windows:  [np.int64(9), np.int64(10)]\n",
            "\n",
            "      benign      :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 20447\n",
            "         Std: 19494\n",
            "\n",
            "      bruteforce  :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 507\n",
            "         Std: 407\n",
            "\n",
            "      ddos        :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 5718\n",
            "         Std: 4769\n",
            "\n",
            "      dos         :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 6138\n",
            "         Std: 5058\n",
            "\n",
            "      malware     :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 2524\n",
            "         Std: 2040\n",
            "\n",
            "      mitm        :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 2600\n",
            "         Std: 2092\n",
            "\n",
            "      recon       :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 9508\n",
            "         Std: 7890\n",
            "\n",
            "      web         :\n",
            "         Appears in 8 windows\n",
            "         Avg per window: 841\n",
            "         Std: 680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tahapan 2 Complete!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nkGFBmO-vJA",
        "outputId": "19e19089-4e01-43e3-8639-6766bb0998e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahapan 2 Complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21467"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tahapan 3: Feature Engineering"
      ],
      "metadata": {
        "id": "whwUHn-vs8KQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 Time Window Features**"
      ],
      "metadata": {
        "id": "1iMe37YTtRPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lightweight_temporal_features(df):\n",
        "    \"\"\"\n",
        "    Create lightweight temporal features\n",
        "    Only add 5 aggregate features to minimize overhead\n",
        "    \"\"\"\n",
        "    print(\"   Creating temporal aggregate features...\")\n",
        "\n",
        "    # Sort by time_window and label\n",
        "    df = df.sort_values(['label2', 'time_window']).reset_index(drop=True)\n",
        "\n",
        "    # Get numeric columns (exclude label and time_window)\n",
        "    numeric_cols = [col for col in df.select_dtypes(include=['float32', 'int32']).columns\n",
        "                   if col not in ['label2', 'time_window']]\n",
        "\n",
        "    # Create 5 aggregate features only\n",
        "    temporal_features = []\n",
        "\n",
        "    # 1. Trend indicator (3-window moving average)\n",
        "    df['trend_indicator'] = df.groupby('label2')[numeric_cols[0]]\\\n",
        "        .rolling(window=3, min_periods=1).mean()\\\n",
        "        .reset_index(0, drop=True).astype('float32')\n",
        "    temporal_features.append('trend_indicator')\n",
        "\n",
        "    # 2. Volatility indicator (3-window moving std)\n",
        "    df['volatility_indicator'] = df.groupby('label2')[numeric_cols[0]]\\\n",
        "        .rolling(window=3, min_periods=1).std()\\\n",
        "        .reset_index(0, drop=True).fillna(0).astype('float32')\n",
        "    temporal_features.append('volatility_indicator')\n",
        "\n",
        "    # 3-5. Rolling stats for top 3 important features (we'll use first 3 numeric)\n",
        "    for i, col in enumerate(numeric_cols[:3], 1):\n",
        "        feat_name = f'roll_mean_{i}'\n",
        "        df[feat_name] = df.groupby('label2')[col]\\\n",
        "            .rolling(window=3, min_periods=1).mean()\\\n",
        "            .reset_index(0, drop=True).astype('float32')\n",
        "        temporal_features.append(feat_name)\n",
        "\n",
        "    print(f\"   Created {len(temporal_features)} temporal features\")\n",
        "    print(f\"   New shape: {df.shape}\")\n",
        "\n",
        "    return df, temporal_features\n",
        "\n",
        "# Apply to train and test (OPTIONAL - uncomment if you want to use)\n",
        "# train_df, temporal_features = create_lightweight_temporal_features(train_df)\n",
        "# test_df, _ = create_lightweight_temporal_features(test_df)\n",
        "\n",
        "print(\"   [SKIPPED] Temporal features are optional for memory efficiency\")\n",
        "temporal_features = []  # Empty list if not used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCvahYiQ-6-w",
        "outputId": "a6917d12-9fd7-403e-856d-73d7e21bee3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   [SKIPPED] Temporal features are optional for memory efficiency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Feature Scaling/Normalization**"
      ],
      "metadata": {
        "id": "6P1lhIUotZSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_features(train_df, test_df, exclude_cols=['label2', 'time_window']):\n",
        "    \"\"\"\n",
        "    Normalize features using StandardScaler\n",
        "    Fit on train, transform both train and test\n",
        "    \"\"\"\n",
        "    print(\"   Normalizing features...\")\n",
        "\n",
        "    # Get feature columns\n",
        "    feature_cols = [col for col in train_df.columns if col not in exclude_cols]\n",
        "\n",
        "    # Initialize scaler\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Fit on train\n",
        "    train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
        "\n",
        "    # Transform test\n",
        "    test_df[feature_cols] = scaler.transform(test_df[feature_cols])\n",
        "\n",
        "    print(f\"   Normalized {len(feature_cols)} features\")\n",
        "    print(f\"   Scaler mean: {scaler.mean_[:5]}\")  # Show first 5\n",
        "    print(f\"   Scaler std:  {scaler.scale_[:5]}\")\n",
        "\n",
        "    return train_df, test_df, scaler, feature_cols\n",
        "\n",
        "# Apply normalization\n",
        "train_df, test_df, scaler, feature_cols = normalize_features(train_df, test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujz4qQQQ_LRA",
        "outputId": "2bacd988-9731-4e92-ddfd-b5d9732b3867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Normalizing features...\n",
            "   Normalized 71 features\n",
            "   Scaler mean: [93.03921535 95.34549739 89.46821287  1.87706113  0.44116353]\n",
            "   Scaler std:  [261.98432792 264.64097313 255.84577702  19.74976552   0.63967933]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 Feature Validation**"
      ],
      "metadata": {
        "id": "9Xdmtosptg95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_features(train_df, test_df, feature_cols):\n",
        "    \"\"\"Validate features after engineering\"\"\"\n",
        "\n",
        "    print(\"   Post-engineering validation:\")\n",
        "\n",
        "    # Check for NaN\n",
        "    train_nan = train_df[feature_cols].isnull().sum().sum()\n",
        "    test_nan = test_df[feature_cols].isnull().sum().sum()\n",
        "    print(f\"      Train NaN: {train_nan}\")\n",
        "    print(f\"      Test NaN:  {test_nan}\")\n",
        "\n",
        "    # Check for Inf\n",
        "    train_inf = np.isinf(train_df[feature_cols].select_dtypes(include=['float32'])).sum().sum()\n",
        "    test_inf = np.isinf(test_df[feature_cols].select_dtypes(include=['float32'])).sum().sum()\n",
        "    print(f\"      Train Inf: {train_inf}\")\n",
        "    print(f\"      Test Inf:  {test_inf}\")\n",
        "\n",
        "    # Check value ranges\n",
        "    print(f\"\\n   Value ranges (first 5 features):\")\n",
        "    for col in feature_cols[:5]:\n",
        "        print(f\"      {col:40s}: [{train_df[col].min():.3f}, {train_df[col].max():.3f}]\")\n",
        "\n",
        "    print(f\"\\n   Features validated successfully\")\n",
        "\n",
        "# Call validation\n",
        "validate_features(train_df, test_df, feature_cols)"
      ],
      "metadata": {
        "id": "j7_IDgi5_aUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30a23f7-0702-4705-9165-5e26caca694f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Post-engineering validation:\n",
            "      Train NaN: 0\n",
            "      Test NaN:  0\n",
            "      Train Inf: 0.0\n",
            "      Test Inf:  0.0\n",
            "\n",
            "   Value ranges (first 5 features):\n",
            "      log_data-ranges_avg                     : [-0.355, 7.279]\n",
            "      log_data-ranges_max                     : [-0.360, 7.197]\n",
            "      log_data-ranges_min                     : [-0.353, 7.468]\n",
            "      log_data-ranges_std_deviation           : [-0.095, 41.839]\n",
            "      log_data-types_count                    : [-0.690, 2.437]\n",
            "\n",
            "   Features validated successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4 Pelatihan Model Baseline untuk Benchmark Performa**"
      ],
      "metadata": {
        "id": "XYXsWsA0x55y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Memulai pelatihan model baseline untuk mendapatkan F1-Score benchmark...\")\n",
        "\n",
        "# Siapkan data original (sebelum augmentasi)\n",
        "X_train_original = train_df[feature_cols].values\n",
        "# Initialize LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train_original_encoded = le.fit_transform(train_df['label2']) # Gunakan LabelEncoder di sini\n",
        "X_test_original = test_df[feature_cols].values\n",
        "y_test_original_encoded = le.transform(test_df['label2'])\n",
        "\n",
        "# Latih model baseline yang cepat, misalnya RandomForest\n",
        "print(\"  - Melatih RandomForest baseline...\")\n",
        "baseline_model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
        "baseline_model.fit(X_train_original, y_train_original_encoded)\n",
        "baseline_pred = baseline_model.predict(X_test_original)\n",
        "\n",
        "# Hitung dan simpan F1-score per kelas\n",
        "print(\"  - Menghitung F1-Score baseline...\")\n",
        "baseline_report = classification_report(y_test_original_encoded, baseline_pred,\n",
        "                                       target_names=le.classes_,\n",
        "                                       output_dict=True)\n",
        "\n",
        "baseline_f1_scores = {cls: baseline_report[cls]['f1-score']\n",
        "                      for cls in le.classes_}\n",
        "\n",
        "print(\"\\nSkor F1-Score Baseline yang akan digunakan untuk A-FIGS:\")\n",
        "for cls, f1 in baseline_f1_scores.items():\n",
        "    print(f\"    {cls:12s}: {f1:.4f}\")\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FupH-tngx1hK",
        "outputId": "777db03d-fc5d-4e5d-fdd0-a1e1d82d5169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai pelatihan model baseline untuk mendapatkan F1-Score benchmark...\n",
            "  - Melatih RandomForest baseline...\n",
            "  - Menghitung F1-Score baseline...\n",
            "\n",
            "Skor F1-Score Baseline yang akan digunakan untuk A-FIGS:\n",
            "    benign      : 0.9952\n",
            "    bruteforce  : 1.0000\n",
            "    ddos        : 0.9968\n",
            "    dos         : 0.9974\n",
            "    malware     : 0.9962\n",
            "    mitm        : 0.9993\n",
            "    recon       : 0.9931\n",
            "    web         : 0.9995\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Base line\n",
        "print(\"Confusion Matrix Baseline:\")\n",
        "print(classification_report(y_test_original_encoded, baseline_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFS3Pck28sP2",
        "outputId": "79ad49bf-f105-4454-bb6a-9d1911130fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix Baseline:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.99      1.00      1.00     15734\n",
            "  bruteforce       1.00      1.00      1.00       571\n",
            "        ddos       1.00      0.99      1.00      6097\n",
            "         dos       1.00      1.00      1.00      6362\n",
            "     malware       1.00      1.00      1.00      2773\n",
            "        mitm       1.00      1.00      1.00      2750\n",
            "       recon       1.00      0.99      0.99     10096\n",
            "         web       1.00      1.00      1.00       936\n",
            "\n",
            "    accuracy                           1.00     45319\n",
            "   macro avg       1.00      1.00      1.00     45319\n",
            "weighted avg       1.00      1.00      1.00     45319\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature columns\n",
        "feature_cols = [col for col in train_df.columns if col not in ['label2', 'time_window']]\n",
        "\n",
        "# Calculate hash for train and test\n",
        "print(f\"\\nCalculating feature hashes...\")\n",
        "print(f\"  Train samples: {len(train_df):,}\")\n",
        "print(f\"  Test samples:  {len(test_df):,}\")\n",
        "\n",
        "test_hash = test_df[feature_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
        "train_hash = train_df[feature_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
        "\n",
        "# Check overlap\n",
        "overlap = test_hash.isin(train_hash).sum()\n",
        "overlap_pct = (overlap / len(test_df)) * 100\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  Test rows with same features in train: {overlap:,} / {len(test_df):,}\")\n",
        "print(f\"  Leakage percentage: {overlap_pct:.2f}%\")\n",
        "\n",
        "if overlap == 0:\n",
        "    print(f\"\\n✅ SUCCESS! NO DATA LEAKAGE!\")\n",
        "elif overlap_pct < 1.0:\n",
        "    print(f\"\\n⚠️  Minor leakage detected ({overlap_pct:.2f}%)\")\n",
        "    print(f\"   This is acceptable (< 1%)\")\n",
        "else:\n",
        "    print(f\"\\n🚨 SIGNIFICANT LEAKAGE! ({overlap_pct:.2f}%)\")\n",
        "    print(f\"   Need to investigate!\")\n",
        "\n",
        "# Show leakage distribution by class\n",
        "if overlap > 0:\n",
        "    print(f\"\\nLeakage by class:\")\n",
        "    leaked_indices = test_df.index[test_hash.isin(train_hash)]\n",
        "    leaked_df = test_df.loc[leaked_indices]\n",
        "\n",
        "    for label in sorted(leaked_df['label2'].unique()):\n",
        "        count = (leaked_df['label2'] == label).sum()\n",
        "        total = (test_df['label2'] == label).sum()\n",
        "        pct = (count / total) * 100\n",
        "        print(f\"  {label:12s}: {count:5,} / {total:5,} ({pct:5.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzbWRyRdHbKq",
        "outputId": "839cd876-97fb-4a77-cde5-f09b196163c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating feature hashes...\n",
            "  Train samples: 386,274\n",
            "  Test samples:  45,319\n",
            "\n",
            "Results:\n",
            "  Test rows with same features in train: 0 / 45,319\n",
            "  Leakage percentage: 0.00%\n",
            "\n",
            "✅ SUCCESS! NO DATA LEAKAGE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# HARDER BASELINE TEST - Add Noise\n",
        "# ============================================================================\n",
        "print(\"\\n[Testing] Baseline with noisy test set...\")\n",
        "\n",
        "# Add small random noise to test set\n",
        "np.random.seed(42)\n",
        "# Use X_test_original which was defined earlier\n",
        "X_test_noisy = X_test_original.copy()\n",
        "\n",
        "# Add 5% Gaussian noise\n",
        "noise_level = 0.05\n",
        "for i in range(X_test_noisy.shape[1]):\n",
        "    # Calculate noise based on the original test set's standard deviation\n",
        "    noise = np.random.normal(0, X_test_original[:, i].std() * noise_level, X_test_noisy.shape[0])\n",
        "    X_test_noisy[:, i] = X_test_noisy[:, i] + noise\n",
        "\n",
        "# Test baseline on noisy data\n",
        "baseline_pred_noisy = baseline_model.predict(X_test_noisy)\n",
        "\n",
        "# Calculate metrics\n",
        "from sklearn.metrics import classification_report\n",
        "# Use y_test_original_encoded which was defined earlier\n",
        "print(\"\\nBaseline Performance on NOISY Test Set:\")\n",
        "print(classification_report(y_test_original_encoded, baseline_pred_noisy, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLZMIrA4IB4J",
        "outputId": "4f658769-0b17-4697-a5e5-880805c6379e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Testing] Baseline with noisy test set...\n",
            "\n",
            "Baseline Performance on NOISY Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.89      0.76      0.82     15734\n",
            "  bruteforce       0.42      0.23      0.30       571\n",
            "        ddos       0.55      0.95      0.70      6097\n",
            "         dos       0.48      0.48      0.48      6362\n",
            "     malware       0.77      0.76      0.77      2773\n",
            "        mitm       0.72      0.18      0.29      2750\n",
            "       recon       0.83      0.91      0.87     10096\n",
            "         web       0.96      0.36      0.52       936\n",
            "\n",
            "    accuracy                           0.73     45319\n",
            "   macro avg       0.70      0.58      0.59     45319\n",
            "weighted avg       0.75      0.73      0.72     45319\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Cross-Validation on Training Set\n",
        "# ============================================================================\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print(\"\\n[Cross-Validation] 5-Fold CV on training set...\")\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1),\n",
        "    X_train_original,\n",
        "    y_train_original_encoded, # Use y_train_original_encoded\n",
        "    cv=5,\n",
        "    scoring='f1_macro'\n",
        ")\n",
        "\n",
        "print(f\"CV F1-Scores: {cv_scores}\")\n",
        "print(f\"Mean F1: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGL6I0O1Icoa",
        "outputId": "f37d578d-785b-486c-c63e-ebcc0d645e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Cross-Validation] 5-Fold CV on training set...\n",
            "CV F1-Scores: [0.9496531  0.90647012 0.97516816 0.98736327 0.96190946]\n",
            "Mean F1: 0.9561 (+/- 0.0279)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SANITY CHECK - Shuffle Test\n",
        "# ============================================================================\n",
        "print(\"\\n[Sanity Check] Testing with shuffled labels...\")\n",
        "\n",
        "# Shuffle test labels (should get ~12.5% accuracy for 8 classes)\n",
        "y_test_shuffled = np.random.permutation(y_test_original_encoded)\n",
        "\n",
        "baseline_acc_shuffled = accuracy_score(y_test_shuffled, baseline_pred)\n",
        "print(f\"Accuracy with shuffled labels: {baseline_acc_shuffled:.4f}\")\n",
        "print(f\"Expected (random): ~{1/len(le.classes_):.4f}\")\n",
        "\n",
        "if baseline_acc_shuffled > 0.2:\n",
        "    print(\"⚠️  WARNING: Accuracy too high with shuffled labels!\")\n",
        "    print(\"   This suggests overfitting or data leakage!\")\n",
        "else:\n",
        "    print(\"✓ Sanity check passed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FOi3dcYIo0a",
        "outputId": "3ad7f049-c5ca-4158-f545-c305476c13eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Sanity Check] Testing with shuffled labels...\n",
            "Accuracy with shuffled labels: 0.2136\n",
            "Expected (random): ~0.1250\n",
            "⚠️  WARNING: Accuracy too high with shuffled labels!\n",
            "   This suggests overfitting or data leakage!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tahapan 3 Complete!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "zQ106y42_i7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd0e1b0-a01b-444f-cda4-8eaf0ae59507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahapan 3 Complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tahapan 4: GIR Calculation"
      ],
      "metadata": {
        "id": "u7sFvb9ut49Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1 Define Severity Weights**"
      ],
      "metadata": {
        "id": "hRz25xYktODZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IIoT severity weights based on impact analysis\n",
        "severity_weights = {\n",
        "    'malware': 5.0,      # Highest: Persistent threat, data exfiltration, Stuxnet-like\n",
        "    'dos': 4.5,          # Safety-critical: Can halt industrial operations\n",
        "    'mitm': 4.5,         # Data integrity: Sensor data manipulation\n",
        "    'ddos': 4.0,         # Infrastructure: Network availability\n",
        "    'bruteforce': 3.5,   # Credential: Lateral movement risk\n",
        "    'web': 3.0,          # Application-layer: Less critical in IIoT\n",
        "    'recon': 2.5,        # Pre-attack: Reconnaissance phase\n",
        "    'benign': 1.0        # Normal traffic\n",
        "}\n",
        "\n",
        "print(\"   IIoT Severity Weights (Higher = More Critical):\")\n",
        "for label, weight in sorted(severity_weights.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"      {label:12s}: {weight:.1f}\")"
      ],
      "metadata": {
        "id": "oH2EbURa_s3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7511cca2-c524-416d-96b7-341069d6b130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   IIoT Severity Weights (Higher = More Critical):\n",
            "      malware     : 5.0\n",
            "      dos         : 4.5\n",
            "      mitm        : 4.5\n",
            "      ddos        : 4.0\n",
            "      bruteforce  : 3.5\n",
            "      web         : 3.0\n",
            "      recon       : 2.5\n",
            "      benign      : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Calculate GIR per Class**"
      ],
      "metadata": {
        "id": "gABK81JluJ8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_adaptive_gir(train_df, severity_weights):\n",
        "    \"\"\"\n",
        "    Calculate Adaptive GIR with severity weighting\n",
        "\n",
        "    Formula: GIR = (w_severity × n_maj) / (1.0 × n_min)\n",
        "\n",
        "    Unlike FIGS original (fixed w_min=2), A-FIGS uses dynamic severity weights\n",
        "    \"\"\"\n",
        "    class_counts = train_df['label2'].value_counts()\n",
        "    n_maj = class_counts.max()  # Majority class count\n",
        "\n",
        "    gir_values = {}\n",
        "    for label in class_counts.index:\n",
        "        n_min = class_counts[label]\n",
        "        w_severity = severity_weights.get(label, 1.0)\n",
        "\n",
        "        # A-FIGS Formula\n",
        "        gir = (w_severity * n_maj) / (1.0 * n_min)\n",
        "        gir_values[label] = gir\n",
        "\n",
        "    return gir_values"
      ],
      "metadata": {
        "id": "VVg-a2fI_2cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate GIR\n",
        "gir_values = calculate_adaptive_gir(train_df, severity_weights)\n",
        "\n",
        "print(\"Adaptive GIR Values:\")\n",
        "for label, gir in sorted(gir_values.items(), key=lambda x: x[1], reverse=True):\n",
        "    count = (train_df['label2'] == label).sum()\n",
        "    print(f\"      {label:12s}: GIR={gir:8.2f} (n={count:7,}, w={severity_weights[label]:.1f})\")"
      ],
      "metadata": {
        "id": "N1knCqJ1_9dZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488a0bef-d0a2-4c24-cd23-a08e7bb55b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaptive GIR Values:\n",
            "      bruteforce  : GIR=  189.56 (n=  4,619, w=3.5)\n",
            "      web         : GIR=  105.02 (n=  7,146, w=3.0)\n",
            "      malware     : GIR=   60.29 (n= 20,747, w=5.0)\n",
            "      mitm        : GIR=   52.38 (n= 21,493, w=4.5)\n",
            "      dos         : GIR=   22.59 (n= 49,841, w=4.5)\n",
            "      ddos        : GIR=   21.05 (n= 47,529, w=4.0)\n",
            "      recon       : GIR=    7.39 (n= 84,591, w=2.5)\n",
            "      benign      : GIR=    1.00 (n=250,160, w=1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3 Categorize (Plentiful/Limited/Sparse) Conservative GIR Thresholds**"
      ],
      "metadata": {
        "id": "vR0TqmINuRQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_by_gir_conservative(gir_values, baseline_f1_scores):\n",
        "    \"\"\"\n",
        "    Categorization konservatif:\n",
        "    - Hanya augmentasi jika F1 < 0.95 (performa buruk)\n",
        "    - Gunakan ambang batas persentil yang lebih ketat\n",
        "    \"\"\"\n",
        "    gir_list = list(gir_values.values())\n",
        "\n",
        "    # Ambang batas lebih ketat: 20% dan 50%\n",
        "    p20 = np.percentile(gir_list, 20)\n",
        "    p50 = np.percentile(gir_list, 50)\n",
        "\n",
        "    categories = {}\n",
        "\n",
        "    for label, gir in gir_values.items():\n",
        "        # Cek performa baseline terlebih dahulu\n",
        "        f1 = baseline_f1_scores.get(label, 0) # Ambil F1 score\n",
        "\n",
        "        # Jika performa sudah bagus (F1 > 0.95), jangan augmentasi\n",
        "        if f1 > 0.95:\n",
        "            categories[label] = 'Plentiful'\n",
        "            continue\n",
        "\n",
        "        # Jika tidak, gunakan GIR\n",
        "        if gir < p20:\n",
        "            categories[label] = 'Plentiful'\n",
        "        elif gir < p50:\n",
        "            categories[label] = 'Limited'\n",
        "        else:\n",
        "            categories[label] = 'Sparse'\n",
        "\n",
        "    return categories, p20, p50"
      ],
      "metadata": {
        "id": "Vp-xG3TsALgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kategorisasi dengan pendekatan konservatif\n",
        "categories, p33, p67 = categorize_by_gir_conservative(gir_values, baseline_f1_scores) # p33 dan p67 sekarang adalah p20 dan p50\n",
        "\n",
        "print(f\"   GIR Percentiles (Konservatif):\")\n",
        "print(f\"      20th percentile: {p20:.2f}\") # Ganti label print\n",
        "print(f\"      50th percentile: {p50:.2f}\") # Ganti label print\n",
        "\n",
        "print(f\"\\n   Class Categories (Konservatif):\")\n",
        "for category_name in ['Plentiful', 'Limited', 'Sparse']:\n",
        "    classes = [label for label, cat in categories.items() if cat == category_name]\n",
        "    print(f\"\\n      {category_name}:\")\n",
        "    for label in classes:\n",
        "        count = (train_df['label2'] == label).sum()\n",
        "        f1 = baseline_f1_scores.get(label)\n",
        "        print(f\"         {label:12s} (n={count:7,}, GIR={gir_values[label]:6.2f}, F1={f1:.3f})\")\n",
        "\n",
        "# Store for later use\n",
        "plentiful_classes = [label for label, cat in categories.items() if cat == 'Plentiful']\n",
        "limited_classes = [label for label, cat in categories.items() if cat == 'Limited']\n",
        "sparse_classes = [label for label, cat in categories.items() if cat == 'Sparse']"
      ],
      "metadata": {
        "id": "EIj-e6rYAO0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1379270a-1bb9-4004-9442-6757f18ad8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   GIR Percentiles (Konservatif):\n",
            "      20th percentile: 12.86\n",
            "      50th percentile: 37.48\n",
            "\n",
            "   Class Categories (Konservatif):\n",
            "\n",
            "      Plentiful:\n",
            "         benign       (n=250,160, GIR=  1.00, F1=0.996)\n",
            "         recon        (n= 84,591, GIR=  7.39, F1=0.992)\n",
            "         dos          (n= 49,841, GIR= 22.59, F1=0.998)\n",
            "         ddos         (n= 47,529, GIR= 21.05, F1=0.997)\n",
            "         mitm         (n= 21,493, GIR= 52.38, F1=0.999)\n",
            "         malware      (n= 20,747, GIR= 60.29, F1=0.996)\n",
            "         web          (n=  7,146, GIR=105.02, F1=0.999)\n",
            "         bruteforce   (n=  4,619, GIR=189.56, F1=1.000)\n",
            "\n",
            "      Limited:\n",
            "\n",
            "      Sparse:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.4 Visualization**"
      ],
      "metadata": {
        "id": "D57-hqqruWYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_gir_analysis(gir_values, categories, severity_weights, save_path='gir_analysis.png'):\n",
        "    \"\"\"Visualize GIR analysis\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    # 1. GIR values bar plot\n",
        "    labels = list(gir_values.keys())\n",
        "    girs = [gir_values[label] for label in labels]\n",
        "    colors = ['green' if categories[label]=='Plentiful'\n",
        "              else 'orange' if categories[label]=='Limited'\n",
        "              else 'red' for label in labels]\n",
        "\n",
        "    axes[0, 0].barh(labels, girs, color=colors, edgecolor='black')\n",
        "    axes[0, 0].set_xlabel('GIR Value')\n",
        "    axes[0, 0].set_title('Adaptive GIR per Class')\n",
        "    axes[0, 0].grid(axis='x', alpha=0.3)\n",
        "    axes[0, 0].axvline(p33, color='blue', linestyle='--', label='33rd percentile')\n",
        "    axes[0, 0].axvline(p67, color='purple', linestyle='--', label='67th percentile')\n",
        "    axes[0, 0].legend()\n",
        "\n",
        "    # 2. Severity weights\n",
        "    weights = [severity_weights[label] for label in labels]\n",
        "    axes[0, 1].barh(labels, weights, color='steelblue', edgecolor='black')\n",
        "    axes[0, 1].set_xlabel('Severity Weight')\n",
        "    axes[0, 1].set_title('IIoT Severity Weights')\n",
        "    axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # 3. Category distribution\n",
        "    category_counts = {}\n",
        "    for cat in ['Plentiful', 'Limited', 'Sparse']:\n",
        "        category_counts[cat] = sum(1 for c in categories.values() if c == cat)\n",
        "\n",
        "    axes[1, 0].pie(category_counts.values(), labels=category_counts.keys(),\n",
        "                   autopct='%1.1f%%', colors=['green', 'orange', 'red'],\n",
        "                   startangle=90, explode=[0.05, 0.05, 0.05])\n",
        "    axes[1, 0].set_title('Class Category Distribution')\n",
        "\n",
        "    # 4. GIR vs Sample Count\n",
        "    counts = [len(train_df[train_df['label2']==label]) for label in labels]\n",
        "    scatter_colors = [colors[i] for i in range(len(labels))]\n",
        "    axes[1, 1].scatter(counts, girs, c=scatter_colors, s=150,\n",
        "                      edgecolors='black', alpha=0.7)\n",
        "    for i, label in enumerate(labels):\n",
        "        axes[1, 1].annotate(label, (counts[i], girs[i]),\n",
        "                           fontsize=9, ha='right')\n",
        "    axes[1, 1].set_xlabel('Sample Count')\n",
        "    axes[1, 1].set_ylabel('GIR Value')\n",
        "    axes[1, 1].set_title('GIR vs Sample Count')\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "    axes[1, 1].set_xscale('log')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"   Saved: {save_path}\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "FBsStMdGAdax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot GIR analysis\n",
        "plot_gir_analysis(gir_values, categories, severity_weights)"
      ],
      "metadata": {
        "id": "oiuSX4cAArjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c306c22-babc-40ec-d5d2-6193bb48670d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Saved: gir_analysis.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tahapan 4 Complete!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "MWo-P5MYAs8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf8fb62-f7b8-43ae-b9ee-8ebd5381cde6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahapan 4 Complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4062"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "7jbB02CZ4hUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tahapan 5: Group-Based Feature Selection"
      ],
      "metadata": {
        "id": "jvRLoKy2tsOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.1 Define Feature Groups**"
      ],
      "metadata": {
        "id": "07pHPhRGu45Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_iiot_feature_groups(train_df):\n",
        "    \"\"\"\n",
        "    Define 9 IIoT-specific feature groups based on CIC-IIoT-2025\n",
        "    \"\"\"\n",
        "    all_cols = [col for col in train_df.columns\n",
        "                if col not in ['label2', 'time_window']]\n",
        "\n",
        "    feature_groups = {\n",
        "        'log_stats': [\n",
        "            col for col in all_cols\n",
        "            if col.startswith('log_') and 'interval' not in col\n",
        "        ],\n",
        "\n",
        "        'packet_rate': [\n",
        "            col for col in all_cols\n",
        "            if 'interval' in col or ('packets_' in col and '_count' in col)\n",
        "        ],\n",
        "\n",
        "        'size_length': [\n",
        "            col for col in all_cols\n",
        "            if any(x in col for x in ['length', 'size', 'mss', 'payload'])\n",
        "               and 'window-size' not in col\n",
        "        ],\n",
        "\n",
        "        'tcp_flags': [\n",
        "            col for col in all_cols if 'tcp-flags' in col\n",
        "        ],\n",
        "\n",
        "        'ip_flags': [\n",
        "            col for col in all_cols if 'ip-flags' in col\n",
        "        ],\n",
        "\n",
        "        'address_diversity': [\n",
        "            col for col in all_cols\n",
        "            if any(x in col for x in ['ips_', 'macs_']) and '_count' in col\n",
        "        ],\n",
        "\n",
        "        'network_multiplexing': [\n",
        "            col for col in all_cols\n",
        "            if any(x in col for x in ['ports_', 'protocols_']) and '_count' in col\n",
        "        ],\n",
        "\n",
        "        'timing_control': [\n",
        "            col for col in all_cols\n",
        "            if any(x in col for x in ['time-delta', 'ttl', 'window-size'])\n",
        "        ],\n",
        "\n",
        "        'fragmentation': [\n",
        "            col for col in all_cols if 'fragment' in col\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Print summary\n",
        "    print(\"Feature Groups Defined:\")\n",
        "    total_features = 0\n",
        "    for group_name, features in feature_groups.items():\n",
        "        print(f\"      {group_name:25s}: {len(features):2d} features\")\n",
        "        total_features += len(features)\n",
        "\n",
        "    print(f\"\\nTotal features: {total_features}\")\n",
        "\n",
        "    return feature_groups\n",
        "\n",
        "# Define groups\n",
        "feature_groups = define_iiot_feature_groups(train_df)"
      ],
      "metadata": {
        "id": "eoqxEEPg4q4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfc2b82-6841-4fb9-8b98-59d5cecb857b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Groups Defined:\n",
            "      log_stats                :  6 features\n",
            "      packet_rate              :  5 features\n",
            "      size_length              : 20 features\n",
            "      tcp_flags                : 10 features\n",
            "      ip_flags                 :  4 features\n",
            "      address_diversity        :  6 features\n",
            "      network_multiplexing     :  6 features\n",
            "      timing_control           : 12 features\n",
            "      fragmentation            :  2 features\n",
            "\n",
            "Total features: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define groups\n",
        "feature_groups = define_iiot_feature_groups(train_df)"
      ],
      "metadata": {
        "id": "yHh_-znZ45iX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59785f3a-6d27-4e68-ae6c-ddf4f5391a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Groups Defined:\n",
            "      log_stats                :  6 features\n",
            "      packet_rate              :  5 features\n",
            "      size_length              : 20 features\n",
            "      tcp_flags                : 10 features\n",
            "      ip_flags                 :  4 features\n",
            "      address_diversity        :  6 features\n",
            "      network_multiplexing     :  6 features\n",
            "      timing_control           : 12 features\n",
            "      fragmentation            :  2 features\n",
            "\n",
            "Total features: 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.2 Sensitivity Analysis per Group**"
      ],
      "metadata": {
        "id": "rnrdFS0Rv_mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Lightweight Discriminator for sensitivity analysis\n",
        "    Memory-efficient architecture\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleDiscriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "Fu3jrxGm5Qxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator_for_class(X_class, X_benign, epochs=20, batch_size=512):\n",
        "    \"\"\"\n",
        "    Train a simple discriminator to distinguish attack class from benign\n",
        "    Used for sensitivity analysis\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Prepare data\n",
        "    X_attack = torch.FloatTensor(X_class.values).to(device)\n",
        "    X_normal = torch.FloatTensor(X_benign.values).to(device)\n",
        "\n",
        "    # Labels: 1 for attack, 0 for benign\n",
        "    y_attack = torch.ones(len(X_attack), 1).to(device)\n",
        "    y_normal = torch.zeros(len(X_normal), 1).to(device)\n",
        "\n",
        "    # Combine\n",
        "    X_combined = torch.cat([X_attack, X_normal], dim=0)\n",
        "    y_combined = torch.cat([y_attack, y_normal], dim=0)\n",
        "\n",
        "    # Shuffle\n",
        "    indices = torch.randperm(len(X_combined))\n",
        "    X_combined = X_combined[indices]\n",
        "    y_combined = y_combined[indices]\n",
        "\n",
        "    # Create DataLoader\n",
        "    dataset = TensorDataset(X_combined, y_combined)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Initialize discriminator\n",
        "    discriminator = SimpleDiscriminator(X_class.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    # Training loop\n",
        "    discriminator.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = discriminator(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"         Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    return discriminator"
      ],
      "metadata": {
        "id": "rux0O76g5dGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sensitivity_analysis_per_group(discriminator, X_sample, feature_groups,\n",
        "                                   epsilon=1e-5, top_k=5):\n",
        "    \"\"\"\n",
        "    Perform sensitivity analysis PER feature group\n",
        "    Returns top-K features from each group\n",
        "    \"\"\"\n",
        "    device = next(discriminator.parameters()).device\n",
        "    discriminator.eval()\n",
        "\n",
        "    selected_features = {}\n",
        "    all_importance_scores = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for group_name, group_features in feature_groups.items():\n",
        "            # Filter valid features\n",
        "            valid_features = [f for f in group_features if f in X_sample.columns]\n",
        "\n",
        "            if len(valid_features) == 0:\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n      Analyzing {group_name} ({len(valid_features)} features)...\")\n",
        "\n",
        "            importance_scores = {}\n",
        "\n",
        "            # Get baseline output\n",
        "            X_tensor = torch.FloatTensor(X_sample.values).to(device)\n",
        "            baseline_output = discriminator(X_tensor).cpu().numpy()\n",
        "\n",
        "            # Perturb each feature\n",
        "            for feature in valid_features:\n",
        "                feature_idx = X_sample.columns.get_loc(feature)\n",
        "\n",
        "                # Create perturbed copy\n",
        "                X_perturbed = X_sample.copy()\n",
        "                X_perturbed.iloc[:, feature_idx] += epsilon\n",
        "\n",
        "                # Get perturbed output\n",
        "                X_pert_tensor = torch.FloatTensor(X_perturbed.values).to(device)\n",
        "                perturbed_output = discriminator(X_pert_tensor).cpu().numpy()\n",
        "\n",
        "                # Calculate importance\n",
        "                importance = np.abs(perturbed_output - baseline_output).mean()\n",
        "                importance_scores[feature] = importance\n",
        "\n",
        "            # Sort and select top-K\n",
        "            sorted_features = sorted(importance_scores.items(),\n",
        "                                   key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            top_features = [f[0] for f in sorted_features[:top_k]]\n",
        "            selected_features[group_name] = top_features\n",
        "            all_importance_scores[group_name] = importance_scores\n",
        "\n",
        "            print(f\"         Top-{top_k} features:\")\n",
        "            for i, (feat, score) in enumerate(sorted_features[:top_k], 1):\n",
        "                print(f\"            {i}. {feat:40s}: {score:.6f}\")\n",
        "\n",
        "    return selected_features, all_importance_scores"
      ],
      "metadata": {
        "id": "U7GeUQlB5xxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform group-based feature selection for each class category\n",
        "print(\"Starting sensitivity analysis...\")"
      ],
      "metadata": {
        "id": "93ha2JHG55Yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de00e6b2-6e91-47f6-f11f-ec97351c2fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting sensitivity analysis...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data for efficiency (10k samples per class)\n",
        "sample_size = 10000\n",
        "X_benign_sample = train_df[train_df['label2'] == 'benign'][feature_cols].sample(\n",
        "    n=min(sample_size, len(train_df[train_df['label2'] == 'benign'])),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "selected_features_by_class = {}\n",
        "importance_scores_by_class = {}"
      ],
      "metadata": {
        "id": "BmUChtqe5_Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Limited and Sparse classes only (they need augmentation)\n",
        "target_classes = limited_classes + sparse_classes\n",
        "\n",
        "for attack_class in target_classes:\n",
        "    print(f\"Processing class: {attack_class}\")\n",
        "    print(f\"   Category: {categories[attack_class]}\")\n",
        "\n",
        "    # Get attack samples\n",
        "    X_attack = train_df[train_df['label2'] == attack_class][feature_cols]\n",
        "\n",
        "    if len(X_attack) < 100:\n",
        "        print(f\"      WARNING: Only {len(X_attack)} samples, using all\")\n",
        "        X_attack_sample = X_attack\n",
        "    else:\n",
        "        X_attack_sample = X_attack.sample(\n",
        "            n=min(sample_size, len(X_attack)),\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    print(f\"      Training discriminator...\")\n",
        "    discriminator = train_discriminator_for_class(\n",
        "        X_attack_sample, X_benign_sample,\n",
        "        epochs=20, batch_size=256\n",
        "    )\n",
        "\n",
        "    print(f\"\\n      Running sensitivity analysis...\")\n",
        "    selected_feats, importance_scores = sensitivity_analysis_per_group(\n",
        "        discriminator, X_attack_sample, feature_groups,\n",
        "        epsilon=1e-5, top_k=5\n",
        "    )\n",
        "\n",
        "    selected_features_by_class[attack_class] = selected_feats\n",
        "    importance_scores_by_class[attack_class] = importance_scores\n",
        "\n",
        "    # Clear GPU memory\n",
        "    del discriminator\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "ZrOLJ-RW6IgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.3 Select Top-K per Group**"
      ],
      "metadata": {
        "id": "vBk4H3gtwBYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def consolidate_selected_features(selected_features_by_class):\n",
        "    \"\"\"\n",
        "    Consolidate selected features across all classes\n",
        "    \"\"\"\n",
        "    all_selected = set()\n",
        "\n",
        "    for attack_class, group_features in selected_features_by_class.items():\n",
        "        for group_name, features in group_features.items():\n",
        "            all_selected.update(features)\n",
        "\n",
        "    return list(all_selected)\n",
        "\n",
        "# Get all selected features\n",
        "selected_important_features = consolidate_selected_features(selected_features_by_class)\n",
        "\n",
        "print(f\"Total selected features: {len(selected_important_features)}\")\n",
        "print(f\"   Selected from original: {len(feature_cols)} features\")\n",
        "print(f\"   Reduction: {(1 - len(selected_important_features)/len(feature_cols))*100:.1f}%\")"
      ],
      "metadata": {
        "id": "q1Q4JTQI6ct4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9b315d-8a30-41e5-c0b7-04dbcdaa87c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total selected features: 0\n",
            "   Selected from original: 71 features\n",
            "   Reduction: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.4 Validate Selected Features**"
      ],
      "metadata": {
        "id": "UelMNYsdwDSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_selected_features(selected_features, feature_groups):\n",
        "    \"\"\"\n",
        "    Validate feature selection across groups\n",
        "    \"\"\"\n",
        "    print(\"Selected Features per Group:\")\n",
        "\n",
        "    group_distribution = {}\n",
        "    for group_name, group_feats in feature_groups.items():\n",
        "        selected_in_group = [f for f in selected_features if f in group_feats]\n",
        "        group_distribution[group_name] = len(selected_in_group)\n",
        "\n",
        "        if len(selected_in_group) > 0:\n",
        "            pct = (len(selected_in_group) / len(selected_features)) * 100\n",
        "            print(f\"      {group_name:25s}: {len(selected_in_group):2d} ({pct:5.1f}%)\")\n",
        "\n",
        "    return group_distribution\n",
        "\n",
        "# Validate\n",
        "group_distribution = validate_selected_features(\n",
        "    selected_important_features, feature_groups\n",
        ")\n",
        "\n",
        "print(\"\\n Tahapan 5 Complete!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "lGs5NPts60Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d135dba-746d-439b-c865-b1895bb10f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features per Group:\n",
            "\n",
            " Tahapan 5 Complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16564"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tahapan 6: Data Augmentation (FIGS)"
      ],
      "metadata": {
        "id": "mzONOPfBtuqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.1 FIGAN for Limited Classes**"
      ],
      "metadata": {
        "id": "DBEPuCCJw21y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Lightweight Generator for FIGAN\"\"\"\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, output_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminator for FIGAN\"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "MvpvELuZ7ahQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_figan(X_real, selected_features, noise_dim=100, epochs=50,\n",
        "                batch_size=256, save_every=10):\n",
        "    \"\"\"\n",
        "    Train FIGAN for generating synthetic samples\n",
        "    Only generates data for selected important features\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"      Using device: {device}\")\n",
        "\n",
        "    # Filter to selected features only\n",
        "    X_selected = X_real[selected_features].values\n",
        "    n_features = len(selected_features)\n",
        "\n",
        "    # Initialize models\n",
        "    generator = Generator(noise_dim, n_features).to(device)\n",
        "    discriminator = Discriminator(n_features).to(device)\n",
        "\n",
        "    # Optimizers\n",
        "    g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    # Convert to tensor\n",
        "    X_tensor = torch.FloatTensor(X_selected).to(device)\n",
        "\n",
        "    # Training loop\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        discriminator.train()\n",
        "\n",
        "        # Real samples\n",
        "        real_samples = X_tensor[torch.randint(0, len(X_tensor), (batch_size,))]\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "\n",
        "        # Fake samples\n",
        "        noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "        fake_samples = generator(noise)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # Discriminator loss\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        real_loss = criterion(discriminator(real_samples), real_labels)\n",
        "        fake_loss = criterion(discriminator(fake_samples.detach()), fake_labels)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "        g_optimizer.zero_grad()\n",
        "\n",
        "        noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "        fake_samples = generator(noise)\n",
        "        g_loss = criterion(discriminator(fake_samples), real_labels)\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # Record losses\n",
        "        g_losses.append(g_loss.item())\n",
        "        d_losses.append(d_loss.item())\n",
        "\n",
        "        if (epoch + 1) % save_every == 0:\n",
        "            print(f\"         Epoch {epoch+1}/{epochs} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    return generator, discriminator, g_losses, d_losses\n",
        "\n",
        "def generate_synthetic_samples(generator, n_samples, selected_features,\n",
        "                               full_feature_list, noise_dim=100):\n",
        "    \"\"\"\n",
        "    Generate synthetic samples and pad non-selected features with zeros\n",
        "    \"\"\"\n",
        "    device = next(generator.parameters()).device\n",
        "    generator.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(n_samples, noise_dim).to(device)\n",
        "        synthetic_selected = generator(noise).cpu().numpy()\n",
        "\n",
        "    # Create full feature dataframe with zeros\n",
        "    synthetic_df = pd.DataFrame(\n",
        "        np.zeros((n_samples, len(full_feature_list))),\n",
        "        columns=full_feature_list\n",
        "    )\n",
        "\n",
        "    # Fill selected features with generated data\n",
        "    synthetic_df[selected_features] = synthetic_selected\n",
        "\n",
        "    return synthetic_df"
      ],
      "metadata": {
        "id": "78A2LFdt8aUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train FIGAN for each Limited class\n",
        "print(\"Training FIGAN for Limited classes...\")\n",
        "\n",
        "synthetic_data_limited = {}\n",
        "\n",
        "for attack_class in limited_classes:\n",
        "    print(f\"\\n   Class: {attack_class}\")\n",
        "\n",
        "    # Get real samples\n",
        "    X_real = train_df[train_df['label2'] == attack_class][feature_cols]\n",
        "    n_real = len(X_real)\n",
        "\n",
        "    # Get selected features for this class\n",
        "    if attack_class in selected_features_by_class:\n",
        "        class_selected_features = consolidate_selected_features(\n",
        "            {attack_class: selected_features_by_class[attack_class]}\n",
        "        )\n",
        "    else:\n",
        "        # Fallback to all selected features\n",
        "        class_selected_features = selected_important_features\n",
        "\n",
        "    print(f\"      Using {len(class_selected_features)} selected features\")\n",
        "    print(f\"      Real samples: {n_real}\")\n",
        "\n",
        "    # Calculate target samples (balance to majority class)\n",
        "    n_majority = (train_df['label2'] == 'benign').sum()\n",
        "    n_target = int(n_majority * 0.5)  # Target 50% of majority\n",
        "    n_generate = max(0, n_target - n_real)\n",
        "\n",
        "    if n_generate == 0:\n",
        "        print(f\"      No generation needed (already sufficient)\")\n",
        "        continue\n",
        "\n",
        "    print(f\"      Target samples: {n_target}\")\n",
        "    print(f\"      Will generate: {n_generate} samples\")\n",
        "\n",
        "    # Train FIGAN\n",
        "    print(f\"      Training FIGAN...\")\n",
        "    generator, discriminator, g_losses, d_losses = train_figan(\n",
        "        X_real, class_selected_features,\n",
        "        noise_dim=100, epochs=50, batch_size=256\n",
        "    )\n",
        "\n",
        "    # Generate synthetic samples\n",
        "    print(f\"      Generating synthetic samples...\")\n",
        "    synthetic_df = generate_synthetic_samples(\n",
        "        generator, n_generate, class_selected_features,\n",
        "        feature_cols, noise_dim=100\n",
        "    )\n",
        "\n",
        "    synthetic_data_limited[attack_class] = synthetic_df\n",
        "\n",
        "    print(f\"      ✓ Generated {len(synthetic_df)} samples\")\n",
        "\n",
        "    # Clear memory\n",
        "    del generator, discriminator\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "Z2Y5l7_f8gWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7557fbf2-845e-4360-9132-0111061462e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training FIGAN for Limited classes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.2 FISMOTE for Sparse Classes**\n"
      ],
      "metadata": {
        "id": "M-k62qWYw52K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fismote_generate(X_real, selected_features, full_feature_list,\n",
        "                     n_samples, k_neighbors=5):\n",
        "    \"\"\"\n",
        "    Feature-Importance SMOTE\n",
        "    Generate synthetic samples using SMOTE on selected features only\n",
        "    \"\"\"\n",
        "    print(f\" Using {len(selected_features)} selected features\")\n",
        "\n",
        "    # Extract selected features\n",
        "    X_selected = X_real[selected_features].values\n",
        "\n",
        "    if len(X_real) < k_neighbors:\n",
        "        k_neighbors = max(1, len(X_real) - 1)\n",
        "        print(f\"      Adjusted k_neighbors to {k_neighbors}\")\n",
        "\n",
        "    # Fit NearestNeighbors\n",
        "    nbrs = NearestNeighbors(n_neighbors=k_neighbors, algorithm='auto').fit(X_selected)\n",
        "\n",
        "    # Generate synthetic samples\n",
        "    synthetic_selected = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        # Randomly select a sample\n",
        "        idx = np.random.randint(0, len(X_selected))\n",
        "        sample = X_selected[idx]\n",
        "\n",
        "        # Find k nearest neighbors\n",
        "        distances, indices = nbrs.kneighbors([sample])\n",
        "\n",
        "        # Randomly select a neighbor\n",
        "        neighbor_idx = np.random.choice(indices[0])\n",
        "        neighbor = X_selected[neighbor_idx]\n",
        "\n",
        "        # Interpolate\n",
        "        alpha = np.random.random()\n",
        "        synthetic_sample = sample + alpha * (neighbor - sample)\n",
        "        synthetic_selected.append(synthetic_sample)\n",
        "\n",
        "    synthetic_selected = np.array(synthetic_selected)\n",
        "\n",
        "    # Create full feature dataframe with zeros\n",
        "    synthetic_df = pd.DataFrame(\n",
        "        np.zeros((n_samples, len(full_feature_list))),\n",
        "        columns=full_feature_list\n",
        "    )\n",
        "\n",
        "    # Fill selected features\n",
        "    synthetic_df[selected_features] = synthetic_selected\n",
        "\n",
        "    return synthetic_df"
      ],
      "metadata": {
        "id": "sql1dPtF8H4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data for Sparse classes\n",
        "print(\"Generating synthetic data for Sparse classes...\")\n",
        "\n",
        "synthetic_data_sparse = {}\n",
        "\n",
        "for attack_class in sparse_classes:\n",
        "    print(f\"\\n   Class: {attack_class}\")\n",
        "\n",
        "    # Get real samples\n",
        "    X_real = train_df[train_df['label2'] == attack_class][feature_cols]\n",
        "    n_real = len(X_real)\n",
        "\n",
        "    # Get selected features\n",
        "    if attack_class in selected_features_by_class:\n",
        "        class_selected_features = consolidate_selected_features(\n",
        "            {attack_class: selected_features_by_class[attack_class]}\n",
        "        )\n",
        "    else:\n",
        "        class_selected_features = selected_important_features\n",
        "\n",
        "    print(f\"   Real samples: {n_real}\")\n",
        "    print(f\"   Using {len(class_selected_features)} selected features\")\n",
        "\n",
        "    # Calculate target samples\n",
        "    n_majority = (train_df['label2'] == 'benign').sum()\n",
        "    n_target = int(n_majority * 0.2)  # Target 20% of majority for sparse\n",
        "    n_generate = max(0, n_target - n_real)\n",
        "\n",
        "    if n_generate == 0:\n",
        "        print(f\"  No generation needed\")\n",
        "        continue\n",
        "\n",
        "    print(f\"  Target samples: {n_target}\")\n",
        "    print(f\"  Will generate: {n_generate} samples\")\n",
        "\n",
        "    # Generate using FISMOTE\n",
        "    print(f\"  Generating with FISMOTE...\")\n",
        "    synthetic_df = fismote_generate(\n",
        "        X_real, class_selected_features, feature_cols,\n",
        "        n_generate, k_neighbors=min(5, n_real-1)\n",
        "    )\n",
        "\n",
        "    synthetic_data_sparse[attack_class] = synthetic_df\n",
        "\n",
        "    print(f\" Generated {len(synthetic_df)} samples\")"
      ],
      "metadata": {
        "id": "fI1yXfn582Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fa2c4c-cb73-4ad2-d7ef-1584ae99a646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic data for Sparse classes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.3 Merge Augmented Data**"
      ],
      "metadata": {
        "id": "VC2497ufw8qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_augmented_data(train_df, synthetic_data_limited, synthetic_data_sparse,\n",
        "                        plentiful_classes, limited_classes, sparse_classes):\n",
        "    \"\"\"\n",
        "    Merge original and synthetic data\n",
        "    \"\"\"\n",
        "    augmented_dfs = []\n",
        "\n",
        "    # Add Plentiful classes (no augmentation)\n",
        "    for attack_class in plentiful_classes:\n",
        "        class_df = train_df[train_df['label2'] == attack_class].copy()\n",
        "        augmented_dfs.append(class_df)\n",
        "        print(f\"      {attack_class:12s} (Plentiful): {len(class_df):7,} samples (original)\")\n",
        "\n",
        "    # Add Limited classes (with FIGAN synthetic)\n",
        "    for attack_class in limited_classes:\n",
        "        class_df = train_df[train_df['label2'] == attack_class].copy()\n",
        "        original_count = len(class_df)\n",
        "\n",
        "        if attack_class in synthetic_data_limited:\n",
        "            synthetic_df = synthetic_data_limited[attack_class].copy()\n",
        "            synthetic_df['label2'] = attack_class\n",
        "            synthetic_df['time_window'] = class_df['time_window'].mode()[0]\n",
        "\n",
        "            augmented_dfs.append(class_df)\n",
        "            augmented_dfs.append(synthetic_df)\n",
        "\n",
        "            total_count = original_count + len(synthetic_df)\n",
        "            print(f\"      {attack_class:12s} (Limited):   {original_count:7,} + {len(synthetic_df):7,} = {total_count:7,}\")\n",
        "        else:\n",
        "            augmented_dfs.append(class_df)\n",
        "            print(f\"      {attack_class:12s} (Limited):   {original_count:7,} (no augmentation)\")\n",
        "\n",
        "    # Add Sparse classes (with FISMOTE synthetic)\n",
        "    for attack_class in sparse_classes:\n",
        "        class_df = train_df[train_df['label2'] == attack_class].copy()\n",
        "        original_count = len(class_df)\n",
        "\n",
        "        if attack_class in synthetic_data_sparse:\n",
        "            synthetic_df = synthetic_data_sparse[attack_class].copy()\n",
        "            synthetic_df['label2'] = attack_class\n",
        "            synthetic_df['time_window'] = class_df['time_window'].mode()[0]\n",
        "\n",
        "            augmented_dfs.append(class_df)\n",
        "            augmented_dfs.append(synthetic_df)\n",
        "\n",
        "            total_count = original_count + len(synthetic_df)\n",
        "            print(f\"      {attack_class:12s} (Sparse):    {original_count:7,} + {len(synthetic_df):7,} = {total_count:7,}\")\n",
        "        else:\n",
        "            augmented_dfs.append(class_df)\n",
        "            print(f\"      {attack_class:12s} (Sparse):    {original_count:7,} (no augmentation)\")\n",
        "\n",
        "    # Concatenate all\n",
        "    train_augmented = pd.concat(augmented_dfs, ignore_index=True)\n",
        "\n",
        "    return train_augmented"
      ],
      "metadata": {
        "id": "HwPxRGb07yWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge data\n",
        "print(\"Merging augmented data...\")\n",
        "train_augmented = merge_augmented_data(\n",
        "    train_df, synthetic_data_limited, synthetic_data_sparse,\n",
        "    plentiful_classes, limited_classes, sparse_classes\n",
        ")\n",
        "\n",
        "print(f\"\\n Augmentation Summary:\")\n",
        "print(f\"      Original train size: {len(train_df):,}\")\n",
        "print(f\"      Augmented train size: {len(train_augmented):,}\")\n",
        "print(f\"      Increase: {len(train_augmented) - len(train_df):,} samples ({((len(train_augmented)/len(train_df))-1)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "TbahoMdj9I3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec98677-2c42-4718-94e4-a3d92029a730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging augmented data...\n",
            "      benign       (Plentiful): 250,160 samples (original)\n",
            "      recon        (Plentiful):  84,591 samples (original)\n",
            "      dos          (Plentiful):  49,841 samples (original)\n",
            "      ddos         (Plentiful):  47,529 samples (original)\n",
            "      mitm         (Plentiful):  21,493 samples (original)\n",
            "      malware      (Plentiful):  20,747 samples (original)\n",
            "      web          (Plentiful):   7,146 samples (original)\n",
            "      bruteforce   (Plentiful):   4,619 samples (original)\n",
            "\n",
            " Augmentation Summary:\n",
            "      Original train size: 486,126\n",
            "      Augmented train size: 486,126\n",
            "      Increase: 0 samples (0.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.4 Validate Synthetic Data Quality**"
      ],
      "metadata": {
        "id": "gNUBn2WZw-dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_synthetic_quality(train_original, train_augmented):\n",
        "    \"\"\"\n",
        "    Validate quality of synthetic data\n",
        "    \"\"\"\n",
        "    print(\"  Statistical Validation:\")\n",
        "\n",
        "    for attack_class in limited_classes + sparse_classes:\n",
        "        real_data = train_original[train_original['label2'] == attack_class][feature_cols]\n",
        "        aug_data = train_augmented[train_augmented['label2'] == attack_class][feature_cols]\n",
        "\n",
        "        if len(real_data) == len(aug_data):\n",
        "            continue  # No synthetic data generated\n",
        "\n",
        "        synthetic_data = aug_data.iloc[len(real_data):]  # Only synthetic\n",
        "\n",
        "        print(f\"\\n      {attack_class}:\")\n",
        "        print(f\"         Real samples: {len(real_data)}\")\n",
        "        print(f\"         Synthetic samples: {len(synthetic_data)}\")\n",
        "\n",
        "        # Compare distributions (first 5 features)\n",
        "        for feat in feature_cols[:5]:\n",
        "            real_mean = real_data[feat].mean()\n",
        "            synth_mean = synthetic_data[feat].mean()\n",
        "            diff_pct = abs((synth_mean - real_mean) / (real_mean + 1e-10)) * 100\n",
        "\n",
        "            print(f\"         {feat:40s}: Real={real_mean:7.3f}, Synth={synth_mean:7.3f}, Diff={diff_pct:5.1f}%\")\n",
        "\n",
        "# Validate\n",
        "validate_synthetic_quality(train_df, train_augmented)\n",
        "\n",
        "print(\"\\n Tahapan 6 Complete!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "BH2ssgoi7lR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92278bc-9c21-456c-9ccf-d61d9b666cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Statistical Validation:\n",
            "\n",
            " Tahapan 6 Complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tahapan 7: Model Training\n",
        "\n"
      ],
      "metadata": {
        "id": "z7NhyEKltwsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "print(\"Preparing training data...\")\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train_augmented = le.fit_transform(train_augmented['label2'])\n",
        "y_test = le.transform(test_df['label2'])\n",
        "\n",
        "X_train_augmented = train_augmented[feature_cols].values\n",
        "X_test = test_df[feature_cols].values\n",
        "\n",
        "print(f\"  X_train shape: {X_train_augmented.shape}\")\n",
        "print(f\"  X_test shape:  {X_test.shape}\")\n",
        "print(f\"  Classes: {le.classes_}\")"
      ],
      "metadata": {
        "id": "mEf4GR6UNmM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bccb9681-2df5-493e-e78d-25f0a5fb72f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing training data...\n",
            "  X_train shape: (486126, 71)\n",
            "  X_test shape:  (60516, 71)\n",
            "  Classes: ['benign' 'bruteforce' 'ddos' 'dos' 'malware' 'mitm' 'recon' 'web']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.1 XGBoost Training**"
      ],
      "metadata": {
        "id": "HypYxPfQyP-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_xgboost(X_train, y_train, X_test, y_test, n_classes):\n",
        "    \"\"\"\n",
        "    Train XGBoost classifier with optimized parameters\n",
        "    \"\"\"\n",
        "    print(\"Initializing XGBoost...\")\n",
        "\n",
        "    xgb_params = {\n",
        "        'objective': 'multi:softmax',\n",
        "        'num_class': n_classes,\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.1,\n",
        "        'n_estimators': 100,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'random_state': 42,\n",
        "        'tree_method': 'hist',  # Faster for large datasets\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBClassifier(**xgb_params)\n",
        "\n",
        "    print(\"      Training XGBoost...\")\n",
        "    model.fit(X_train, y_train,\n",
        "             eval_set=[(X_test, y_test)],\n",
        "             verbose=False)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(f\"      Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"      Test Accuracy:  {test_acc:.4f}\")\n",
        "\n",
        "    return model, y_pred_test"
      ],
      "metadata": {
        "id": "jGK4a20tR6m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBoost\n",
        "xgb_model, xgb_pred = train_xgboost(\n",
        "    X_train_augmented, y_train_augmented,\n",
        "    X_test, y_test, len(le.classes_)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al4EsJipSAF7",
        "outputId": "8bc205a7-8bb6-4c41-e6b6-3601e76e7b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing XGBoost...\n",
            "      Training XGBoost...\n",
            "      Train Accuracy: 0.9743\n",
            "      Test Accuracy:  0.9834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan Hasil Model\n",
        "joblib.dump(xgb_model, \"/content/drive/MyDrive/Dataset/CIC_IIoT_2025/Brave/xgb_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rKgLc2ESKEj",
        "outputId": "694899c8-9d12-4292-ba9f-404b8ac4cf6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Dataset/CIC_IIoT_2025/Brave/xgb_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menload Kembali Hasil Model\n",
        "xgb_model = joblib.load(\"/content/drive/MyDrive/Dataset/CIC_IIoT_2025/Brave/xgb_model.pkl\")\n",
        "\n",
        "print(\"Model berhasil di load\")"
      ],
      "metadata": {
        "id": "JRAczdUITaNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.2 LightGBM Training**\n"
      ],
      "metadata": {
        "id": "DYToN0jPygmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lightgbm(X_train, y_train, X_test, y_test, n_classes):\n",
        "    \"\"\"\n",
        "    Train LightGBM classifier with optimized parameters\n",
        "    \"\"\"\n",
        "    print(\"Initializing LightGBM...\")\n",
        "\n",
        "    lgb_params = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': n_classes,\n",
        "        'max_depth': 6,\n",
        "        'learning_rate': 0.1,\n",
        "        'n_estimators': 100,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'verbose': -1\n",
        "    }\n",
        "\n",
        "    model = lgb.LGBMClassifier(**lgb_params)\n",
        "\n",
        "    print(\"      Training LightGBM...\")\n",
        "    model.fit(X_train, y_train,\n",
        "             eval_set=[(X_test, y_test)],\n",
        "             eval_metric='multi_logloss',\n",
        "             callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)])\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(f\"      Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"      Test Accuracy:  {test_acc:.4f}\")\n",
        "\n",
        "    return model, y_pred_test"
      ],
      "metadata": {
        "id": "xQ0VdfjrT6TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LightGBM\n",
        "lgb_model, lgb_pred = train_lightgbm(\n",
        "    X_train_augmented, y_train_augmented,\n",
        "    X_test, y_test, len(le.classes_)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niVpoeUxT-Ez",
        "outputId": "22cb9507-2b3f-4cd8-9b39-3d6d9b30dbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing LightGBM...\n",
            "      Training LightGBM...\n",
            "      Train Accuracy: 0.9788\n",
            "      Test Accuracy:  0.9874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan Hasil Model\n",
        "joblib.dump(lgb_model, \"/content/drive/MyDrive/Dataset/CIC_IIoT_2025/Brave/lgb_model.pkl\")\n",
        "\n",
        "print(\"Model berhasil disimpan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg7dsFmtU8bz",
        "outputId": "b43d69c8-6dcc-454f-fd40-00af2497a080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model berhasil disimpan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menload Kembali Hasil Model\n",
        "lgb_model = joblib.load(\"/content/drive/MyDrive/Dataset/CIC_IIoT_2025/Brave/lgb_model.pkl\")\n",
        "\n",
        "print(\"Model berhasil diload Kembali\")"
      ],
      "metadata": {
        "id": "7qYB1WOWVLUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.3 Random Forest Training**"
      ],
      "metadata": {
        "id": "jmB3-2FfyjEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_random_forest(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train Random Forest classifier\n",
        "    \"\"\"\n",
        "    print(\"Initializing Random Forest...\")\n",
        "\n",
        "    rf_params = {\n",
        "        'n_estimators': 100,\n",
        "        'max_depth': 20,\n",
        "        'min_samples_split': 5,\n",
        "        'min_samples_leaf': 2,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'verbose': 0\n",
        "    }\n",
        "\n",
        "    model = RandomForestClassifier(**rf_params)\n",
        "\n",
        "    print(\"      Training Random Forest...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "    print(f\"      Train Accuracy: {train_acc:.4f}\")\n",
        "    print(f\"      Test Accuracy:  {test_acc:.4f}\")\n",
        "\n",
        "    return model, y_pred_test"
      ],
      "metadata": {
        "id": "on9Q5mZIVaXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Random Forest\n",
        "rf_model, rf_pred = train_random_forest(\n",
        "    X_train_augmented, y_train_augmented,\n",
        "    X_test, y_test\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSJGp2lWVdPa",
        "outputId": "f87baa3c-aee7-4344-de1e-17a97e8c11e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Random Forest...\n",
            "      Training Random Forest...\n",
            "      Train Accuracy: 0.9796\n",
            "      Test Accuracy:  0.9851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan Hasil Model\n",
        "joblib.dump(rf_model, \"/content/drive/MyDrive/Dataset/CIC_IIoT_2025/Brave/rf_model.pkl\")\n",
        "\n",
        "print(\"Model berhasil disimpan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHI18blfV1q7",
        "outputId": "27adc328-6d4e-4f1c-a045-ac5eeaf5f422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model berhasil disimpan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menload Kembali Hasil Model\n",
        "rf_model = joblib.load(\"/content/drive/MyDrive/Dataset/CIC_IIoT_2025/Brave/rf_model.pkl\")\n",
        "\n",
        "print(\"Model berhasil diload Kembali\")"
      ],
      "metadata": {
        "id": "suWU0EY7WC6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tahapan 7 Complete!\")\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PKnkAoAVz9a",
        "outputId": "aa5d8bdb-06f6-4b1d-c7f8-d5cbd3f6fc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahapan 7 Complete!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "# Memori Tersedia\n",
        "memory_available = psutil.virtual_memory().available\n",
        "\n",
        "# Konversi ke GB\n",
        "memory_available_gb = memory_available / (1024 ** 3)\n",
        "\n",
        "print(f\"Jumlah memori yang tersedia: {memory_available_gb:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_nJWsuIXJ5j",
        "outputId": "a17fc140-08ea-4c11-d9e4-415278bf281b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah memori yang tersedia: 7.30 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tahapan 8: Evaluation"
      ],
      "metadata": {
        "id": "bPXGbmavtyvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.1 Predictions on Test Set**"
      ],
      "metadata": {
        "id": "yyvDFk-SzBer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_dict = {\n",
        "    'XGBoost': xgb_pred,\n",
        "    'LightGBM': lgb_pred,\n",
        "    'Random Forest': rf_pred\n",
        "}\n",
        "\n",
        "print(\"Predictions collected for all models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNJfGzSSY0i2",
        "outputId": "86ebd528-73f9-4c9a-cf33-068fda81e5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions collected for all models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.2 Metrics Calculation (per class)**"
      ],
      "metadata": {
        "id": "awaPWLWZzUD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics_per_class(y_true, y_pred, label_encoder):\n",
        "    \"\"\"\n",
        "    Calculate comprehensive metrics for each class\n",
        "    \"\"\"\n",
        "    # Get class names\n",
        "    classes = label_encoder.classes_\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        y_true, y_pred, labels=range(len(classes)), zero_division=0\n",
        "    )\n",
        "\n",
        "    # Overall metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "    # Macro/Weighted averages\n",
        "    macro_precision = precision.mean()\n",
        "    macro_recall = recall.mean()\n",
        "    macro_f1 = f1.mean()\n",
        "\n",
        "    weighted_precision = (precision * support).sum() / support.sum()\n",
        "    weighted_recall = (recall * support).sum() / support.sum()\n",
        "    weighted_f1 = (f1 * support).sum() / support.sum()\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame({\n",
        "        'Class': classes,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Support': support\n",
        "    })\n",
        "\n",
        "    # Add overall metrics\n",
        "    overall_metrics = {\n",
        "        'Accuracy': accuracy,\n",
        "        'MCC': mcc,\n",
        "        'Macro Precision': macro_precision,\n",
        "        'Macro Recall': macro_recall,\n",
        "        'Macro F1': macro_f1,\n",
        "        'Weighted Precision': weighted_precision,\n",
        "        'Weighted Recall': weighted_recall,\n",
        "        'Weighted F1': weighted_f1\n",
        "    }\n",
        "\n",
        "    return results_df, overall_metrics"
      ],
      "metadata": {
        "id": "VRamSeieZCpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for all models\n",
        "all_results = {}\n",
        "\n",
        "for model_name, y_pred in predictions_dict.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "\n",
        "    results_df, overall_metrics = calculate_metrics_per_class(\n",
        "        y_test, y_pred, le\n",
        "    )\n",
        "\n",
        "    all_results[model_name] = {\n",
        "        'per_class': results_df,\n",
        "        'overall': overall_metrics\n",
        "    }\n",
        "\n",
        "    # Print per-class results\n",
        "    print(\"\\n      Per-Class Metrics:\")\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Print overall metrics\n",
        "    print(\"\\n      Overall Metrics:\")\n",
        "    for metric, value in overall_metrics.items():\n",
        "        print(f\"         {metric:20s}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMCK4IJcZIqz",
        "outputId": "e7e16e55-b91a-4f77-b943-ee449dc8ec78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "XGBoost:\n",
            "\n",
            "      Per-Class Metrics:\n",
            "     Class  Precision   Recall  F1-Score  Support\n",
            "    benign   0.973596 0.999032  0.986150    27903\n",
            "bruteforce   0.998557 0.976023  0.987161      709\n",
            "      ddos   0.997620 0.978065  0.987745     6428\n",
            "       dos   0.986732 0.991267  0.988994     6527\n",
            "   malware   0.991975 0.982377  0.987153     2894\n",
            "      mitm   0.989875 0.992555  0.991213     2955\n",
            "     recon   0.991815 0.946485  0.968620    12034\n",
            "       web   1.000000 0.955910  0.977458     1066\n",
            "\n",
            "      Overall Metrics:\n",
            "         Accuracy            : 0.9834\n",
            "         MCC                 : 0.9770\n",
            "         Macro Precision     : 0.9913\n",
            "         Macro Recall        : 0.9777\n",
            "         Macro F1            : 0.9843\n",
            "         Weighted Precision  : 0.9836\n",
            "         Weighted Recall     : 0.9834\n",
            "         Weighted F1         : 0.9833\n",
            "\n",
            "LightGBM:\n",
            "\n",
            "      Per-Class Metrics:\n",
            "     Class  Precision   Recall  F1-Score  Support\n",
            "    benign   0.978924 0.998781  0.988753    27903\n",
            "bruteforce   0.992938 0.991537  0.992237      709\n",
            "      ddos   0.997011 0.985843  0.991395     6428\n",
            "       dos   0.991589 0.993412  0.992500     6527\n",
            "   malware   0.996863 0.988252  0.992539     2894\n",
            "      mitm   0.994609 0.998985  0.996792     2955\n",
            "     recon   0.994894 0.955293  0.974692    12034\n",
            "       web   1.000000 0.986867  0.993390     1066\n",
            "\n",
            "      Overall Metrics:\n",
            "         Accuracy            : 0.9874\n",
            "         MCC                 : 0.9825\n",
            "         Macro Precision     : 0.9934\n",
            "         Macro Recall        : 0.9874\n",
            "         Macro F1            : 0.9903\n",
            "         Weighted Precision  : 0.9875\n",
            "         Weighted Recall     : 0.9874\n",
            "         Weighted F1         : 0.9873\n",
            "\n",
            "Random Forest:\n",
            "\n",
            "      Per-Class Metrics:\n",
            "     Class  Precision   Recall  F1-Score  Support\n",
            "    benign   0.971465 0.999283  0.985178    27903\n",
            "bruteforce   0.998538 0.963329  0.980617      709\n",
            "      ddos   0.999529 0.990666  0.995078     6428\n",
            "       dos   0.995401 0.994791  0.995096     6527\n",
            "   malware   0.996157 0.985142  0.990618     2894\n",
            "      mitm   0.997297 0.998985  0.998140     2955\n",
            "     recon   0.997631 0.944657  0.970421    12034\n",
            "       web   1.000000 0.955910  0.977458     1066\n",
            "\n",
            "      Overall Metrics:\n",
            "         Accuracy            : 0.9851\n",
            "         MCC                 : 0.9795\n",
            "         Macro Precision     : 0.9945\n",
            "         Macro Recall        : 0.9791\n",
            "         Macro F1            : 0.9866\n",
            "         Weighted Precision  : 0.9855\n",
            "         Weighted Recall     : 0.9851\n",
            "         Weighted F1         : 0.9851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.3 Confusion Matrix**"
      ],
      "metadata": {
        "id": "ohvOu5JHzeOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, label_encoder, model_name,\n",
        "                         save_path=None):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix heatmap\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    classes = label_encoder.classes_\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=classes, yticklabels=classes,\n",
        "                cbar_kws={'label': 'Count'})\n",
        "\n",
        "    plt.title(f'Confusion Matrix - {model_name}', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "\n",
        "    # Add accuracy in title\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    plt.suptitle(f'Accuracy: {accuracy:.4f}', y=0.98, fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"      Saved: {save_path}\")\n",
        "\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "Uq9e6QryaMKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrices for all models\n",
        "for model_name, y_pred in predictions_dict.items():\n",
        "    print(f\"\\n   Generating confusion matrix for {model_name}...\")\n",
        "    save_path = f'confusion_matrix_{model_name.lower().replace(\" \", \"_\")}.png'\n",
        "    plot_confusion_matrix(y_test, y_pred, le, model_name, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OVRAUVbaPbL",
        "outputId": "83ba787a-4eee-4f3f-b1fd-d7c1b61816d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   Generating confusion matrix for XGBoost...\n",
            "      Saved: confusion_matrix_xgboost.png\n",
            "\n",
            "   Generating confusion matrix for LightGBM...\n",
            "      Saved: confusion_matrix_lightgbm.png\n",
            "\n",
            "   Generating confusion matrix for Random Forest...\n",
            "      Saved: confusion_matrix_random_forest.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.4 Comparison with Baseline**"
      ],
      "metadata": {
        "id": "aYJcXVrRze9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_baseline_models(X_train_original, y_train_original, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Train baseline models WITHOUT augmentation for comparison\n",
        "    \"\"\"\n",
        "    print(\"      Training baseline XGBoost (no augmentation)...\")\n",
        "\n",
        "    xgb_baseline = xgb.XGBClassifier(\n",
        "        objective='multi:softmax',\n",
        "        num_class=len(np.unique(y_train_original)),\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        tree_method='hist',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    xgb_baseline.fit(X_train_original, y_train_original, verbose=False)\n",
        "    baseline_pred = xgb_baseline.predict(X_test)\n",
        "\n",
        "    return baseline_pred"
      ],
      "metadata": {
        "id": "ez_PWETPasuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare baseline data (original train without augmentation)\n",
        "X_train_original = train_df[feature_cols].values\n",
        "y_train_original = le.transform(train_df['label2'])"
      ],
      "metadata": {
        "id": "zdzAX4gYa1sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train baseline\n",
        "baseline_pred = train_baseline_models(\n",
        "    X_train_original, y_train_original, X_test, y_test\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QIdd8NMa5W7",
        "outputId": "e2c234f5-e1ea-4e9f-9945-fc218633c359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Training baseline XGBoost (no augmentation)...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate baseline metrics\n",
        "print(\"Baseline Model (No Augmentation):\")\n",
        "baseline_results, baseline_overall = calculate_metrics_per_class(\n",
        "    y_test, baseline_pred, le\n",
        ")\n",
        "\n",
        "print(\"\\n      Per-Class Metrics:\")\n",
        "print(baseline_results.to_string(index=False))\n",
        "\n",
        "print(\"\\n      Overall Metrics:\")\n",
        "for metric, value in baseline_overall.items():\n",
        "    print(f\"         {metric:20s}: {value:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx9m3PW6bBCT",
        "outputId": "e51bcb0d-d85a-4b11-a493-30a7783f9674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Model (No Augmentation):\n",
            "\n",
            "      Per-Class Metrics:\n",
            "     Class  Precision   Recall  F1-Score  Support\n",
            "    benign   0.994891 0.997993  0.996440    27903\n",
            "bruteforce   1.000000 1.000000  1.000000      709\n",
            "      ddos   0.999219 0.995644  0.997429     6428\n",
            "       dos   0.997247 0.998928  0.998086     6527\n",
            "   malware   0.997231 0.995508  0.996369     2894\n",
            "      mitm   0.998646 0.998646  0.998646     2955\n",
            "     recon   0.994986 0.989363  0.992167    12034\n",
            "       web   1.000000 0.998124  0.999061     1066\n",
            "\n",
            "      Overall Metrics:\n",
            "         Accuracy            : 0.9961\n",
            "         MCC                 : 0.9945\n",
            "         Macro Precision     : 0.9978\n",
            "         Macro Recall        : 0.9968\n",
            "         Macro F1            : 0.9973\n",
            "         Weighted Precision  : 0.9961\n",
            "         Weighted Recall     : 0.9961\n",
            "         Weighted F1         : 0.9961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison table\n",
        "print(\"Performance Comparison (A-FIGS vs Baseline):\")\n",
        "print(\"\\n      Model Comparison (XGBoost):\")\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': list(baseline_overall.keys()),\n",
        "    'Baseline': list(baseline_overall.values()),\n",
        "    'A-FIGS (XGBoost)': list(all_results['XGBoost']['overall'].values())\n",
        "})\n",
        "\n",
        "comparison_df['Improvement'] = (\n",
        "    (comparison_df['A-FIGS (XGBoost)'] - comparison_df['Baseline']) /\n",
        "    comparison_df['Baseline'] * 100\n",
        ")\n",
        "\n",
        "print(comparison_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3e-tT39bOkj",
        "outputId": "72bfa794-635c-4786-b266-1815fcdc4af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Comparison (A-FIGS vs Baseline):\n",
            "\n",
            "      Model Comparison (XGBoost):\n",
            "            Metric  Baseline  A-FIGS (XGBoost)  Improvement\n",
            "          Accuracy  0.996067          0.983376    -1.274097\n",
            "               MCC  0.994536          0.976963    -1.766908\n",
            "   Macro Precision  0.997778          0.991271    -0.652088\n",
            "      Macro Recall  0.996776          0.977714    -1.912320\n",
            "          Macro F1  0.997275          0.984312    -1.299823\n",
            "Weighted Precision  0.996069          0.983619    -1.249913\n",
            "   Weighted Recall  0.996067          0.983376    -1.274097\n",
            "       Weighted F1  0.996065          0.983294    -1.282104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Per-class improvement\n",
        "print(\"Per-Class F1-Score Improvement:\")\n",
        "baseline_f1 = baseline_results.set_index('Class')['F1-Score']\n",
        "afigs_f1 = all_results['XGBoost']['per_class'].set_index('Class')['F1-Score']\n",
        "\n",
        "improvement_df = pd.DataFrame({\n",
        "    'Class': baseline_f1.index,\n",
        "    'Baseline F1': baseline_f1.values,\n",
        "    'A-FIGS F1': afigs_f1.values,\n",
        "    'Improvement': ((afigs_f1.values - baseline_f1.values) /\n",
        "                    (baseline_f1.values + 1e-10) * 100)\n",
        "})\n",
        "\n",
        "print(improvement_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3pQQnSfbR-E",
        "outputId": "ed753d46-2092-4f9d-8abb-08b0a8abc619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-Class F1-Score Improvement:\n",
            "     Class  Baseline F1  A-FIGS F1  Improvement\n",
            "    benign     0.985716   0.985667    -0.004943\n",
            "bruteforce     0.983583   0.983676     0.009477\n",
            "      ddos     0.987831   0.987035    -0.080509\n",
            "       dos     0.989290   0.988068    -0.123540\n",
            "   malware     0.987320   0.984331    -0.302669\n",
            "      mitm     0.987295   0.988525     0.124638\n",
            "     recon     0.966825   0.967596     0.079734\n",
            "       web     0.976967   0.976967     0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Highlight Limited and Sparse classes\n",
        "print(\"Focus on Augmented Classes:\")\n",
        "augmented_classes = limited_classes + sparse_classes\n",
        "for attack_class in augmented_classes:\n",
        "    baseline_f1_val = baseline_f1.get(attack_class, 0)\n",
        "    afigs_f1_val = afigs_f1.get(attack_class, 0)\n",
        "    improvement = ((afigs_f1_val - baseline_f1_val) / (baseline_f1_val + 1e-10) * 100)\n",
        "    category = categories.get(attack_class, 'Unknown')\n",
        "\n",
        "    print(f\"         {attack_class:12s} ({category:8s}): \"\n",
        "          f\"Baseline={baseline_f1_val:.4f}, A-FIGS={afigs_f1_val:.4f}, \"\n",
        "          f\"Improvement={improvement:+6.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_V064gmbeQ6",
        "outputId": "a019a5d2-75d0-4581-bfbd-819980252580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Focus on Augmented Classes:\n",
            "         dos          (Limited ): Baseline=0.9893, A-FIGS=0.9881, Improvement= -0.12%\n",
            "         mitm         (Limited ): Baseline=0.9873, A-FIGS=0.9885, Improvement= +0.12%\n",
            "         malware      (Sparse  ): Baseline=0.9873, A-FIGS=0.9843, Improvement= -0.30%\n",
            "         web          (Sparse  ): Baseline=0.9770, A-FIGS=0.9770, Improvement= +0.00%\n",
            "         bruteforce   (Sparse  ): Baseline=0.9836, A-FIGS=0.9837, Improvement= +0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.5 Visualization & Reporting**"
      ],
      "metadata": {
        "id": "CiIORRCCzf7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model_comparison(all_results, save_path='model_comparison.png'):\n",
        "    \"\"\"\n",
        "    Plot comprehensive model comparison\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    models = list(all_results.keys())\n",
        "\n",
        "    # 1. Overall Accuracy Comparison\n",
        "    accuracies = [all_results[model]['overall']['Accuracy'] for model in models]\n",
        "    axes[0, 0].bar(models, accuracies, color=['steelblue', 'coral', 'lightgreen'],\n",
        "                   edgecolor='black')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].set_title('Overall Accuracy Comparison')\n",
        "    axes[0, 0].set_ylim([0.7, 1.0])\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for i, v in enumerate(accuracies):\n",
        "        axes[0, 0].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "    # 2. MCC Comparison\n",
        "    mccs = [all_results[model]['overall']['MCC'] for model in models]\n",
        "    axes[0, 1].bar(models, mccs, color=['steelblue', 'coral', 'lightgreen'],\n",
        "                   edgecolor='black')\n",
        "    axes[0, 1].set_ylabel('Matthews Correlation Coefficient')\n",
        "    axes[0, 1].set_title('MCC Comparison')\n",
        "    axes[0, 1].set_ylim([0.5, 1.0])\n",
        "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for i, v in enumerate(mccs):\n",
        "        axes[0, 1].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "    # 3. Macro F1-Score Comparison\n",
        "    macro_f1s = [all_results[model]['overall']['Macro F1'] for model in models]\n",
        "    axes[1, 0].bar(models, macro_f1s, color=['steelblue', 'coral', 'lightgreen'],\n",
        "                   edgecolor='black')\n",
        "    axes[1, 0].set_ylabel('Macro F1-Score')\n",
        "    axes[1, 0].set_title('Macro F1-Score Comparison')\n",
        "    axes[1, 0].set_ylim([0.7, 1.0])\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for i, v in enumerate(macro_f1s):\n",
        "        axes[1, 0].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "    # 4. Per-Class F1-Score Comparison (Best model)\n",
        "    best_model = models[np.argmax(accuracies)]\n",
        "    per_class_f1 = all_results[best_model]['per_class']\n",
        "\n",
        "    colors = ['green' if cls in plentiful_classes\n",
        "              else 'orange' if cls in limited_classes\n",
        "              else 'red' for cls in per_class_f1['Class']]\n",
        "\n",
        "    axes[1, 1].barh(per_class_f1['Class'], per_class_f1['F1-Score'],\n",
        "                    color=colors, edgecolor='black')\n",
        "    axes[1, 1].set_xlabel('F1-Score')\n",
        "    axes[1, 1].set_title(f'Per-Class F1-Score ({best_model})')\n",
        "    axes[1, 1].set_xlim([0, 1.1])\n",
        "    axes[1, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # Add legend\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='green', edgecolor='black', label='Plentiful'),\n",
        "        Patch(facecolor='orange', edgecolor='black', label='Limited'),\n",
        "        Patch(facecolor='red', edgecolor='black', label='Sparse')\n",
        "    ]\n",
        "    axes[1, 1].legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"      Saved: {save_path}\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "L_fET_FmcFEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate comparison plot\n",
        "plot_model_comparison(all_results)\n",
        "\n",
        "def plot_baseline_vs_afigs(baseline_results, afigs_results, categories,\n",
        "                           save_path='baseline_vs_afigs.png'):\n",
        "    \"\"\"\n",
        "    Plot detailed baseline vs A-FIGS comparison\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "    classes = baseline_results['Class'].values\n",
        "\n",
        "    # Get category colors\n",
        "    colors = ['green' if cls in plentiful_classes\n",
        "              else 'orange' if cls in limited_classes\n",
        "              else 'red' for cls in classes]\n",
        "\n",
        "    # 1. Precision Comparison\n",
        "    x = np.arange(len(classes))\n",
        "    width = 0.35\n",
        "\n",
        "    axes[0].bar(x - width/2, baseline_results['Precision'], width,\n",
        "                label='Baseline', color='lightgray', edgecolor='black')\n",
        "    axes[0].bar(x + width/2, afigs_results['Precision'], width,\n",
        "                label='A-FIGS', color=colors, edgecolor='black', alpha=0.8)\n",
        "    axes[0].set_ylabel('Precision')\n",
        "    axes[0].set_title('Precision Comparison')\n",
        "    axes[0].set_xticks(x)\n",
        "    axes[0].set_xticklabels(classes, rotation=45, ha='right')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 2. Recall Comparison\n",
        "    axes[1].bar(x - width/2, baseline_results['Recall'], width,\n",
        "                label='Baseline', color='lightgray', edgecolor='black')\n",
        "    axes[1].bar(x + width/2, afigs_results['Recall'], width,\n",
        "                label='A-FIGS', color=colors, edgecolor='black', alpha=0.8)\n",
        "    axes[1].set_ylabel('Recall')\n",
        "    axes[1].set_title('Recall Comparison')\n",
        "    axes[1].set_xticks(x)\n",
        "    axes[1].set_xticklabels(classes, rotation=45, ha='right')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 3. F1-Score Comparison\n",
        "    axes[2].bar(x - width/2, baseline_results['F1-Score'], width,\n",
        "                label='Baseline', color='lightgray', edgecolor='black')\n",
        "    axes[2].bar(x + width/2, afigs_results['F1-Score'], width,\n",
        "                label='A-FIGS', color=colors, edgecolor='black', alpha=0.8)\n",
        "    axes[2].set_ylabel('F1-Score')\n",
        "    axes[2].set_title('F1-Score Comparison')\n",
        "    axes[2].set_xticks(x)\n",
        "    axes[2].set_xticklabels(classes, rotation=45, ha='right')\n",
        "    axes[2].legend()\n",
        "    axes[2].grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add category legend\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_elements = [\n",
        "        Patch(facecolor='green', edgecolor='black', label='Plentiful'),\n",
        "        Patch(facecolor='orange', edgecolor='black', label='Limited'),\n",
        "        Patch(facecolor='red', edgecolor='black', label='Sparse')\n",
        "    ]\n",
        "    axes[2].legend(handles=legend_elements, loc='lower right',\n",
        "                   title='Category', framealpha=0.9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"      Saved: {save_path}\")\n",
        "    plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdpxK6ICcN_D",
        "outputId": "2c64ab27-daf0-4ef2-ff5c-05cc67342470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Saved: model_comparison.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate baseline vs A-FIGS comparison\n",
        "plot_baseline_vs_afigs(\n",
        "    baseline_results,\n",
        "    all_results['XGBoost']['per_class'],\n",
        "    categories\n",
        ")\n",
        "\n",
        "# Generate final summary report\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL SUMMARY REPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. DATASET STATISTICS:\")\n",
        "print(f\"      Original Train: {len(train_df):,} samples\")\n",
        "print(f\"      Augmented Train: {len(train_augmented):,} samples (+{len(train_augmented)-len(train_df):,})\")\n",
        "print(f\"      Test Set: {len(test_df):,} samples\")\n",
        "print(f\"      Features: {len(feature_cols)}\")\n",
        "print(f\"      Selected Features: {len(selected_important_features)} ({(len(selected_important_features)/len(feature_cols)*100):.1f}%)\")\n",
        "\n",
        "print(\"\\n2. CLASS DISTRIBUTION:\")\n",
        "print(f\"      Plentiful: {len(plentiful_classes)} classes - {plentiful_classes}\")\n",
        "print(f\"      Limited:   {len(limited_classes)} classes - {limited_classes}\")\n",
        "print(f\"      Sparse:    {len(sparse_classes)} classes - {sparse_classes}\")\n",
        "\n",
        "print(\"\\n3. AUGMENTATION SUMMARY:\")\n",
        "total_synthetic = 0\n",
        "for attack_class in limited_classes:\n",
        "    if attack_class in synthetic_data_limited:\n",
        "        n_synth = len(synthetic_data_limited[attack_class])\n",
        "        total_synthetic += n_synth\n",
        "        print(f\"      {attack_class:12s} (FIGAN):   +{n_synth:,} samples\")\n",
        "\n",
        "for attack_class in sparse_classes:\n",
        "    if attack_class in synthetic_data_sparse:\n",
        "        n_synth = len(synthetic_data_sparse[attack_class])\n",
        "        total_synthetic += n_synth\n",
        "        print(f\"      {attack_class:12s} (FISMOTE): +{n_synth:,} samples\")\n",
        "\n",
        "print(f\"\\n      Total synthetic samples: {total_synthetic:,}\")\n",
        "\n",
        "print(\"\\n4. MODEL PERFORMANCE (Test Set):\")\n",
        "for model_name in ['XGBoost', 'LightGBM', 'Random Forest']:\n",
        "    metrics = all_results[model_name]['overall']\n",
        "    print(f\"\\n   {model_name}:\")\n",
        "    print(f\"      Accuracy:        {metrics['Accuracy']:.4f}\")\n",
        "    print(f\"      MCC:             {metrics['MCC']:.4f}\")\n",
        "    print(f\"      Macro F1:        {metrics['Macro F1']:.4f}\")\n",
        "    print(f\"      Weighted F1:     {metrics['Weighted F1']:.4f}\")\n",
        "\n",
        "print(\"\\n5. A-FIGS IMPROVEMENT (vs Baseline):\")\n",
        "print(f\"      Accuracy:    {comparison_df.loc[comparison_df['Metric']=='Accuracy', 'Improvement'].values[0]:+.2f}%\")\n",
        "print(f\"      MCC:         {comparison_df.loc[comparison_df['Metric']=='MCC', 'Improvement'].values[0]:+.2f}%\")\n",
        "print(f\"      Macro F1:    {comparison_df.loc[comparison_df['Metric']=='Macro F1', 'Improvement'].values[0]:+.2f}%\")\n",
        "\n",
        "print(\"\\n6. CRITICAL ATTACK DETECTION (Sparse & Limited):\")\n",
        "for attack_class in augmented_classes:\n",
        "    if attack_class in baseline_f1.index and attack_class in afigs_f1.index:\n",
        "        baseline_val = baseline_f1[attack_class]\n",
        "        afigs_val = afigs_f1[attack_class]\n",
        "        improvement = ((afigs_val - baseline_val) / (baseline_val + 1e-10) * 100)\n",
        "        category = categories[attack_class]\n",
        "        severity = severity_weights[attack_class]\n",
        "\n",
        "        print(f\"      {attack_class:12s} | Severity={severity:.1f} | \"\n",
        "              f\"Baseline F1={baseline_val:.4f} | A-FIGS F1={afigs_val:.4f} | \"\n",
        "              f\"Δ={improvement:+6.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCzfV0YEcXVT",
        "outputId": "69bbde5d-3504-4943-8f71-d466698f3c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Saved: baseline_vs_afigs.png\n",
            "\n",
            "================================================================================\n",
            "FINAL SUMMARY REPORT\n",
            "================================================================================\n",
            "\n",
            "1. DATASET STATISTICS:\n",
            "      Original Train: 486,126 samples\n",
            "      Augmented Train: 782,536 samples (+296,410)\n",
            "      Test Set: 60,516 samples\n",
            "      Features: 71\n",
            "      Selected Features: 60 (84.5%)\n",
            "\n",
            "2. CLASS DISTRIBUTION:\n",
            "      Plentiful: 3 classes - ['benign', 'recon', 'ddos']\n",
            "      Limited:   2 classes - ['dos', 'mitm']\n",
            "      Sparse:    3 classes - ['malware', 'web', 'bruteforce']\n",
            "\n",
            "3. AUGMENTATION SUMMARY:\n",
            "      dos          (FIGAN):   +75,239 samples\n",
            "      mitm         (FIGAN):   +103,587 samples\n",
            "      malware      (FISMOTE): +29,285 samples\n",
            "      web          (FISMOTE): +42,886 samples\n",
            "      bruteforce   (FISMOTE): +45,413 samples\n",
            "\n",
            "      Total synthetic samples: 296,410\n",
            "\n",
            "4. MODEL PERFORMANCE (Test Set):\n",
            "\n",
            "   XGBoost:\n",
            "      Accuracy:        0.9825\n",
            "      MCC:             0.9757\n",
            "      Macro F1:        0.9827\n",
            "      Weighted F1:     0.9824\n",
            "\n",
            "   LightGBM:\n",
            "      Accuracy:        0.9866\n",
            "      MCC:             0.9814\n",
            "      Macro F1:        0.9895\n",
            "      Weighted F1:     0.9865\n",
            "\n",
            "   Random Forest:\n",
            "      Accuracy:        0.9857\n",
            "      MCC:             0.9802\n",
            "      Macro F1:        0.9870\n",
            "      Weighted F1:     0.9856\n",
            "\n",
            "5. A-FIGS IMPROVEMENT (vs Baseline):\n",
            "      Accuracy:    -0.02%\n",
            "      MCC:         -0.02%\n",
            "      Macro F1:    -0.04%\n",
            "\n",
            "6. CRITICAL ATTACK DETECTION (Sparse & Limited):\n",
            "      dos          | Severity=4.5 | Baseline F1=0.9893 | A-FIGS F1=0.9881 | Δ= -0.12%\n",
            "      mitm         | Severity=4.5 | Baseline F1=0.9873 | A-FIGS F1=0.9885 | Δ= +0.12%\n",
            "      malware      | Severity=5.0 | Baseline F1=0.9873 | A-FIGS F1=0.9843 | Δ= -0.30%\n",
            "      web          | Severity=3.0 | Baseline F1=0.9770 | A-FIGS F1=0.9770 | Δ= +0.00%\n",
            "      bruteforce   | Severity=3.5 | Baseline F1=0.9836 | A-FIGS F1=0.9837 | Δ= +0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memori Yang Tersedia\n",
        "memory_available = psutil.virtual_memory().available / (1024 ** 3)  # Convert to GB\n",
        "print(f\"Memory yang tersedia: {memory_available:.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l_Z6-LCc_Dz",
        "outputId": "513b1b06-0d31-4d58-e63a-060d2c605bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory yang tersedia: 6.03 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# DATA LEAKAGE CHECK\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA LEAKAGE VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "feature_cols = [col for col in train_df.columns if col not in ['label2', 'time_window']]\n",
        "\n",
        "# 1. Check feature-level overlap\n",
        "print(\"\\n[1] Checking feature duplication between train/test...\")\n",
        "\n",
        "test_hash = test_df[feature_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
        "train_hash = train_df[feature_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
        "\n",
        "overlap = test_hash.isin(train_hash).sum()\n",
        "print(f\"    Test rows with same features in train: {overlap} / {len(test_df)}\")\n",
        "\n",
        "if overlap > 0:\n",
        "    print(f\"    ⚠️ WARNING: {(overlap/len(test_df)*100):.2f}% test data leaked from train!\")\n",
        "else:\n",
        "    print(f\"    ✓ No feature-level leakage detected\")\n",
        "\n",
        "# 2. Check time window separation\n",
        "print(\"\\n[2] Verifying time window separation...\")\n",
        "train_windows = train_df['time_window'].unique()\n",
        "test_windows = test_df['time_window'].unique()\n",
        "\n",
        "print(f\"    Train windows: {sorted(train_windows)}\")\n",
        "print(f\"    Test windows: {sorted(test_windows)}\")\n",
        "\n",
        "window_overlap = set(train_windows) & set(test_windows)\n",
        "if len(window_overlap) > 0:\n",
        "    print(f\"    ⚠️ WARNING: Overlapping windows: {window_overlap}\")\n",
        "else:\n",
        "    print(f\"    ✓ No time window overlap\")\n",
        "\n",
        "# 3. Check if normalization/scaling was done correctly\n",
        "print(\"\\n[3] Feature statistics comparison...\")\n",
        "print(\"    (Train and test should have different distributions)\")\n",
        "\n",
        "sample_features = feature_cols[:5]\n",
        "for feat in sample_features:\n",
        "    train_mean = train_df[feat].mean()\n",
        "    test_mean = test_df[feat].mean()\n",
        "    train_std = train_df[feat].std()\n",
        "    test_std = test_df[feat].std()\n",
        "\n",
        "    print(f\"    {feat[:30]:30s}: Train μ={train_mean:8.2f} σ={train_std:8.2f} | Test μ={test_mean:8.2f} σ={test_std:8.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkgrPtZs-1t6",
        "outputId": "a4b6cb4a-7441-42d4-d1a9-0b6e21f8d09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATA LEAKAGE VERIFICATION\n",
            "============================================================\n",
            "\n",
            "[1] Checking feature duplication between train/test...\n",
            "    Test rows with same features in train: 13770 / 60516\n",
            "    ⚠️ WARNING: 22.75% test data leaked from train!\n",
            "\n",
            "[2] Verifying time window separation...\n",
            "    Train windows: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]\n",
            "    Test windows: [np.int64(9), np.int64(10)]\n",
            "    ✓ No time window overlap\n",
            "\n",
            "[3] Feature statistics comparison...\n",
            "    (Train and test should have different distributions)\n",
            "    log_data-ranges_avg           : Train μ=   -0.00 σ=    1.00 | Test μ=   -0.03 σ=    0.97\n",
            "    log_data-ranges_max           : Train μ=    0.00 σ=    1.00 | Test μ=   -0.02 σ=    0.98\n",
            "    log_data-ranges_min           : Train μ=   -0.00 σ=    1.00 | Test μ=   -0.04 σ=    0.96\n",
            "    log_data-ranges_std_deviation : Train μ=   -0.00 σ=    1.00 | Test μ=    0.03 σ=    1.10\n",
            "    log_data-types_count          : Train μ=   -0.00 σ=    1.00 | Test μ=    0.03 σ=    1.04\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}